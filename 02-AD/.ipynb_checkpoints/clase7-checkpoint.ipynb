{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Clase 7: Modelos de regresión lineal múltiple\n",
    "\n",
    "\n",
    "\n",
    "## Variables categóricas y modelos múltiples: Subastas de Ebay de Mario Kart para Wii\n",
    "\n",
    "Hasta el momento, hemos visto modelos de regresión simple con variables explicativas de tipo numéricas. Pero evidentemente, las variables categóricas también son útiles para predecir resultados. Vamos a introducir el uso de estas variables con el siguiente ejemplo, donde  consideramos un predictor categórico con dos niveles. Tenemos un dataset de subastas de Ebay para un videojuego, Mario Kart para Nintendo Wii, donde se registraron tanto el precio total de la subasta como la condición del juego. Aquí queremos predecir el precio total según la condición del juego, que toma los valores usado y nuevo. Leamos el dataset y exploremos un poco:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>duration</th>\n",
       "      <th>n_bids</th>\n",
       "      <th>cond</th>\n",
       "      <th>start_pr</th>\n",
       "      <th>ship_pr</th>\n",
       "      <th>total_pr</th>\n",
       "      <th>ship_sp</th>\n",
       "      <th>seller_rate</th>\n",
       "      <th>stock_photo</th>\n",
       "      <th>wheels</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150377422259</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>new</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4.00</td>\n",
       "      <td>51.55</td>\n",
       "      <td>standard</td>\n",
       "      <td>1580</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>~~ Wii MARIO KART &amp;amp; WHEEL ~ NINTENDO Wii ~...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>260483376854</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>used</td>\n",
       "      <td>0.99</td>\n",
       "      <td>3.99</td>\n",
       "      <td>37.04</td>\n",
       "      <td>firstClass</td>\n",
       "      <td>365</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Mariokart Wii Nintendo with wheel - Mario Kart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>320432342985</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>new</td>\n",
       "      <td>0.99</td>\n",
       "      <td>3.50</td>\n",
       "      <td>45.50</td>\n",
       "      <td>firstClass</td>\n",
       "      <td>998</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>Mario Kart Wii (Wii)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>280405224677</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>new</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44.00</td>\n",
       "      <td>standard</td>\n",
       "      <td>7</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Brand New Mario Kart Wii Comes with Wheel. Fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170392227765</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>new</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>71.00</td>\n",
       "      <td>media</td>\n",
       "      <td>820</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>BRAND NEW NINTENDO 1 WII MARIO KART WITH 2 WHE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  duration  n_bids  cond  start_pr  ship_pr  total_pr  \\\n",
       "0  150377422259         3      20   new      0.99     4.00     51.55   \n",
       "1  260483376854         7      13  used      0.99     3.99     37.04   \n",
       "2  320432342985         3      16   new      0.99     3.50     45.50   \n",
       "3  280405224677         3      18   new      0.99     0.00     44.00   \n",
       "4  170392227765         1      20   new      0.01     0.00     71.00   \n",
       "\n",
       "      ship_sp  seller_rate stock_photo  wheels  \\\n",
       "0    standard         1580         yes       1   \n",
       "1  firstClass          365         yes       1   \n",
       "2  firstClass          998          no       1   \n",
       "3    standard            7         yes       1   \n",
       "4       media          820         yes       2   \n",
       "\n",
       "                                               title  \n",
       "0  ~~ Wii MARIO KART &amp; WHEEL ~ NINTENDO Wii ~...  \n",
       "1  Mariokart Wii Nintendo with wheel - Mario Kart...  \n",
       "2                               Mario Kart Wii (Wii)  \n",
       "3  Brand New Mario Kart Wii Comes with Wheel. Fre...  \n",
       "4  BRAND NEW NINTENDO 1 WII MARIO KART WITH 2 WHE...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mariokart = pd.read_csv('data/raw/mariokart.csv')\n",
    "mariokart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                int64\n",
       "duration          int64\n",
       "n_bids            int64\n",
       "cond             object\n",
       "start_pr        float64\n",
       "ship_pr         float64\n",
       "total_pr        float64\n",
       "ship_sp          object\n",
       "seller_rate       int64\n",
       "stock_photo      object\n",
       "wheels            int64\n",
       "title            object\n",
       "condition      category\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mariokart.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En principio, para incorporar la variable de condición del juego en una ecuación de regresión, es necesario convertir la(s) categorías a una forma numérica. La manera matemática clásica de hacerlo es usando una variable binaria (o un conjunto de $n-1$ variables binarias para 3 o más categorías de una misma variable), que toma valor 1 cuando la observación tiene una categoría determinada y 0 cuando no la tiene. Estas variables también son típicamente llamadas variables *dummy*.   \n",
    "\n",
    "Luego, creamos una variable llamada `cond_new` que es 1 cuando el juego es nuevo y 0 cuando es usado. Usando esta variable, el modelo lineal podría escribirse como:  \n",
    "\n",
    "$$\\hat{price} = \\beta_0 + \\beta_1 \\cdot cond\\_new $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OJO, `total_pr` es el precio de venta más el precio de envío. \n",
    "Si queremos modelar solo el precio de venta, debemos construir esta variable también"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creando variable cond_new\n",
    "\n",
    "mariokart['cond_new'] = mariokart['cond'].map({'new': 1, 'used': 0})\n",
    "\n",
    "mariokart[['cond','cond_new']].head()\n",
    "\n",
    "# creando variable price\n",
    "\n",
    "mariokart['price'] = mariokart['total_pr']-mariokart['ship_pr']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noten que la variable `cond` está como `object` (está siendo leída como string). En `pandas`, es posible especificar esta variable como un tipo especial llamado `category`, donde se explicita que esta es una variable categórica. Esto tiene muchas ventajas, tales como disminuir tiempos de lectura, de cálculo y de ajuste de modelos, pero por ahora veamos primero como nos funciona nuestra variable dummy creada.  Para hacerlo, se puede usar el método `astype`. Esto se vuelve bien relevante para poder disminuir tiempos de cómputo y para definir variables de base, pero por ahora dejémoslo así y veamos que pasa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustemos un modelo de regresión simple con `statsmodels`. Importamos las librerías correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import statsmodels.formula.api as smf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Noten que llamamos `statsmodels.formula.api` además de `statsmodels.api`.\n",
    "Esto porque `formula.api` contiene muchas de las mismas funciones de `api` (e.g. OLS, GLM), pero también tiene las mismas funciones con minúsculas para la mayoría de estos modelos, ya que estos aceptan argumentos `formula` (tipo `R`) y `df`(dataframes de pandas), mientras que las con mayúscula aceptan las matrices `endog` y `exog`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.022\n",
      "Model:                            OLS   Adj. R-squared:                  0.015\n",
      "Method:                 Least Squares   F-statistic:                     3.204\n",
      "Date:                Sat, 01 Oct 2022   Prob (F-statistic):             0.0756\n",
      "Time:                        07:40:57   Log-Likelihood:                -655.84\n",
      "No. Observations:                 143   AIC:                             1316.\n",
      "Df Residuals:                     141   BIC:                             1322.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     43.7369      2.609     16.764      0.000      38.579      48.895\n",
      "cond_new       7.2709      4.062      1.790      0.076      -0.759      15.301\n",
      "==============================================================================\n",
      "Omnibus:                      270.391   Durbin-Watson:                   2.054\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            54561.172\n",
      "Skew:                           9.075   Prob(JB):                         0.00\n",
      "Kurtosis:                      96.956   Cond. No.                         2.46\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "mod = smf.ols(formula='price ~ cond_new', data=mariokart)\n",
    "res = mod.fit()\n",
    "print(res.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept    43.736905\n",
      "cond_new      7.270892\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Extraemos los parámetros del modelo para luego hacemos un gráfico de los datos y el ajuste\n",
    "\n",
    "params = res.params\n",
    "print(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nax.plot(x, res2.fittedvalues, \"r--.\", label=\"Predicted\")\\nax.plot(x, iv_u, \"r--\")\\nax.plot(x, iv_l, \"r--\")\\nlegend = ax.legend(loc=\"best\")\\nfig = sm.graphics.plot_regress_exog(res, 0, ax=ax)\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "ax.plot(mariokart['cond_new'], mariokart['price'], \"o\", label=\"Data\")\n",
    "ax.plot(mariokart['cond_new'], params['Intercept']+params['cond_new']*mariokart['cond_new']  , \"r-\", label=\"Predicted\")\n",
    "ax.set_ylabel(\"Precio\")\n",
    "ax.set_xlabel(\"Condición\")\n",
    "ax.set_title(\"Regresión de precio en función de condición\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que hay dos outliers bien evidentes. Vamos a explorar que sucede con ellos más adelante. Ahora veamos, ¿Qué pasa si usamos la variable `cond` en vez de `cond_new` en el modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.022\n",
      "Model:                            OLS   Adj. R-squared:                  0.015\n",
      "Method:                 Least Squares   F-statistic:                     3.204\n",
      "Date:                Sat, 01 Oct 2022   Prob (F-statistic):             0.0756\n",
      "Time:                        07:23:57   Log-Likelihood:                -655.84\n",
      "No. Observations:                 143   AIC:                             1316.\n",
      "Df Residuals:                     141   BIC:                             1322.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept       51.0078      3.113     16.385      0.000      44.853      57.162\n",
      "cond[T.used]    -7.2709      4.062     -1.790      0.076     -15.301       0.759\n",
      "==============================================================================\n",
      "Omnibus:                      270.391   Durbin-Watson:                   2.054\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            54561.172\n",
      "Skew:                           9.075   Prob(JB):                         0.00\n",
      "Kurtosis:                      96.956   Cond. No.                         2.88\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "mod2 = smf.ols(formula='price ~ cond', data=mariokart)\n",
    "res2 = mod2.fit()\n",
    "print(res2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noten que el modelo ajustado por `statsmodels` asumió a `cond` como una variable categórica.\n",
    "¿Cómo se comparan ambos modelos? ¿Qué cambia y qué se mantiene?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo interpretamos los estimadores de predictores categóricos?\n",
    "\n",
    "El intercepto estimado es el valor de la variable de respuesta para la primera categoría o categoría de base(es decir, la categoría correspondiente a un valor de indicador de 0). La pendiente estimada es el cambio promedio en la variable de respuesta entre las dos categorías.  \n",
    "\n",
    "Es decir, para el primer modelo, el intercepto es el precio estimado cuando `cond_new` toma valor 0, o sea, cuando el juego es usado. Es decir, el precio de venta promedio de una versión usada del juego es de $43.73 aproximadamente. La pendiente indica que, en promedio, los juegos nuevos se venden por alrededor de $7.27 más que los juegos usados.\n",
    "\n",
    "### Mas de una categoría: creando dummies, o declarando categorías:\n",
    "\n",
    "Hagamos un segundo modelo, donde la variable explicativa sea el método de envío (que tiene más de dos categorías). Acá, la manera matemática de expresar estas categorías es básicamente crear variables *dummies* para cada categoría con excepción de una categoría que la dejamos de base. Esto porque si asumimos que cada observación puede y tiene que tener una sola categoría en esta variable categórica, siempre es posible escribir la última dummy como una combinación lineal de las otras. Dicho de otra manera, como en la variable `ship_sp` las categorías que existen en el dataset son: `['standard', 'firstClass', 'media', 'upsGround', 'priority','parcel', 'other', 'ups3Day']`, si tengo dummies para todas ellas, puedo tomar cualquiera, por ejemplo `upsGround`, y predecirla sin error usando las otras variables, ya que sencillamente `upsGround` tendrá valor 1 cuando todas las demás tengan valor 0 y valor 0 cuando alguna de las demás tenga valor 1. Esta multicolinealidad perfecta impide calcular el determinante de la matriz que calcula los estimadores, quedando con infinitas soluciones, lo que no nos informa nada del modelo. Por tanto, debemos tomar una categoría base para que el modelo pueda ajustar y podamos tener una interpretación de los coeficientes. En principio, podemos elegir cualquier categoría, pero hay que recordar que la interpretación del coeficiente será la comparación de la categoría respecto a la categoría base. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.089\n",
      "Model:                            OLS   Adj. R-squared:                  0.041\n",
      "Method:                 Least Squares   F-statistic:                     1.876\n",
      "Date:                Sat, 01 Oct 2022   Prob (F-statistic):             0.0782\n",
      "Time:                        08:40:11   Log-Likelihood:                -650.81\n",
      "No. Observations:                 143   AIC:                             1318.\n",
      "Df Residuals:                     135   BIC:                             1341.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept               39.2591      5.030      7.805      0.000      29.311      49.207\n",
      "ship_sp[T.media]        10.7702      8.066      1.335      0.184      -5.182      26.722\n",
      "ship_sp[T.other]         6.4042     14.521      0.441      0.660     -22.313      35.122\n",
      "ship_sp[T.parcel]       24.1228      7.752      3.112      0.002       8.792      39.454\n",
      "ship_sp[T.priority]      0.5218      7.036      0.074      0.941     -13.393      14.437\n",
      "ship_sp[T.standard]      5.4836      6.494      0.844      0.400      -7.359      18.326\n",
      "ship_sp[T.ups3Day]       3.7409     24.123      0.155      0.877     -43.968      51.450\n",
      "ship_sp[T.upsGround]    10.2145      6.577      1.553      0.123      -2.793      23.222\n",
      "==============================================================================\n",
      "Omnibus:                      248.822   Durbin-Watson:                   2.066\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            37768.371\n",
      "Skew:                           7.790   Prob(JB):                         0.00\n",
      "Kurtosis:                      81.077   Cond. No.                         13.3\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# veamos este nuevo modelo\n",
    "mod3 = smf.ols(formula='price ~ ship_sp', data=mariokart)\n",
    "res3 = mod3.fit()\n",
    "print(res3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La categoría base es `firstClass`. Cambiemos la categoría base por la categoría con mayor frecuencia. Para ello, podemos cambiar el tipo de variable en pandas, o indicar la categoría base al correr el modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "standard      33\n",
       "upsGround     31\n",
       "priority      23\n",
       "firstClass    22\n",
       "parcel        16\n",
       "media         14\n",
       "other          3\n",
       "ups3Day        1\n",
       "Name: ship_sp, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mariokart['ship_sp'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.089\n",
      "Model:                            OLS   Adj. R-squared:                  0.041\n",
      "Method:                 Least Squares   F-statistic:                     1.876\n",
      "Date:                Sat, 01 Oct 2022   Prob (F-statistic):             0.0782\n",
      "Time:                        09:04:52   Log-Likelihood:                -650.81\n",
      "No. Observations:                 143   AIC:                             1318.\n",
      "Df Residuals:                     135   BIC:                             1341.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=============================================================================================================================\n",
      "                                                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                                    44.7427      4.107     10.894      0.000      36.620      52.865\n",
      "C(ship_sp, Treatment(reference=\"standard\"))[T.firstClass]    -5.4836      6.494     -0.844      0.400     -18.326       7.359\n",
      "C(ship_sp, Treatment(reference=\"standard\"))[T.media]          5.2866      7.525      0.703      0.484      -9.596      20.169\n",
      "C(ship_sp, Treatment(reference=\"standard\"))[T.other]          0.9206     14.227      0.065      0.949     -27.216      29.058\n",
      "C(ship_sp, Treatment(reference=\"standard\"))[T.parcel]        18.6391      7.187      2.593      0.011       4.425      32.853\n",
      "C(ship_sp, Treatment(reference=\"standard\"))[T.priority]      -4.9619      6.409     -0.774      0.440     -17.636       7.712\n",
      "C(ship_sp, Treatment(reference=\"standard\"))[T.ups3Day]       -1.7427     23.948     -0.073      0.942     -49.104      45.619\n",
      "C(ship_sp, Treatment(reference=\"standard\"))[T.upsGround]      4.7308      5.901      0.802      0.424      -6.940      16.402\n",
      "==============================================================================\n",
      "Omnibus:                      248.822   Durbin-Watson:                   2.066\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            37768.371\n",
      "Skew:                           7.790   Prob(JB):                         0.00\n",
      "Kurtosis:                      81.077   Cond. No.                         12.9\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# cambiar categoría base en statmodels y correr modelo\n",
    "mod3a = smf.ols(formula='price ~ C(ship_sp, Treatment(reference = \"standard\"))', data=mariokart)\n",
    "res3a = mod3a.fit()\n",
    "print(res3a.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo interpreto estos coeficientes? ¿Es lo que esperábamos? ¿Por qué?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['firstClass', 'media', 'other', 'parcel', 'priority', 'standard',\n",
       "       'ups3Day', 'upsGround'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cambiar categoría base en pandas\n",
    "mariokart['ship_sp'] = pd.Categorical(mariokart['ship_sp'], categories=mariokart['ship_sp'].unique())\n",
    "# estos datos tienen dos atributos: ordered, que puede ser True o False, \n",
    "# y categories que da el orden de las categorías, donde \n",
    "# si ordered es True, es el orden rankeado de menor a mayor,\n",
    "# y si ordered es False, es por defecto el orden alfabético \n",
    "# y la primera categoría queda como categoría base en cualquier modelo.\n",
    "#mariokart['ship_sp'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['standard', 'firstClass', 'media', 'other', 'parcel', 'priority',\n",
       "       'ups3Day', 'upsGround'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cambiar categoría base a standard\n",
    "\n",
    "\n",
    "mariokart['ship_sp'] = mariokart['ship_sp'].cat.set_categories(['standard','firstClass', 'media', 'other', 'parcel', 'priority', 'ups3Day', 'upsGround'])\n",
    "mariokart['ship_sp'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.089\n",
      "Model:                            OLS   Adj. R-squared:                  0.041\n",
      "Method:                 Least Squares   F-statistic:                     1.876\n",
      "Date:                Sat, 01 Oct 2022   Prob (F-statistic):             0.0782\n",
      "Time:                        09:31:14   Log-Likelihood:                -650.81\n",
      "No. Observations:                 143   AIC:                             1318.\n",
      "Df Residuals:                     135   BIC:                             1341.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                44.7427      4.107     10.894      0.000      36.620      52.865\n",
      "ship_sp[T.firstClass]    -5.4836      6.494     -0.844      0.400     -18.326       7.359\n",
      "ship_sp[T.media]          5.2866      7.525      0.703      0.484      -9.596      20.169\n",
      "ship_sp[T.other]          0.9206     14.227      0.065      0.949     -27.216      29.058\n",
      "ship_sp[T.parcel]        18.6391      7.187      2.593      0.011       4.425      32.853\n",
      "ship_sp[T.priority]      -4.9619      6.409     -0.774      0.440     -17.636       7.712\n",
      "ship_sp[T.ups3Day]       -1.7427     23.948     -0.073      0.942     -49.104      45.619\n",
      "ship_sp[T.upsGround]      4.7308      5.901      0.802      0.424      -6.940      16.402\n",
      "==============================================================================\n",
      "Omnibus:                      248.822   Durbin-Watson:                   2.066\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            37768.371\n",
      "Skew:                           7.790   Prob(JB):                         0.00\n",
      "Kurtosis:                      81.077   Cond. No.                         12.9\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#correr modelo\n",
    "mod3b = smf.ols(formula='price ~ ship_sp', data=mariokart)\n",
    "res3b = mod3b.fit()\n",
    "print(res3b.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Chequeo del modelo y sus supuestos\n",
    "\n",
    "El análisis de robustez o chequeo de supuestos nos permite analizar en qué medida el modelo es una buena representación de las asociaciones entre variables.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para predictores categóricos con solo dos niveles, la suposición de linealidad siempre se cumplirá. Sin embargo, debemos evaluar si los residuos en cada grupo son aproximadamente normales y tienen una varianza aproximadamente igual. Como puede verse en la figura 8.16, los datos de la subasta satisfacen razonablemente estas dos condiciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. **Linealidad:** \n",
    " Debe haber una relación lineal entre la variable explicada y la variable explicativa. Una forma en que se puede expresar la linealidad se relaciona con la **distribución de los residuos**.  \n",
    "   En presencia de linealidad se esperaría que los residuos se distribuyan **aleatoriamente** en torno a la recta de regresión (representada por los valores predichos).  \n",
    " \n",
    " **Detección de problemas:**  \n",
    "Gráfico de valores predichos (en x) contra residuos (en y)\n",
    "\n",
    "* Los residuos deben ser independientes de los valores\n",
    "predichos. \n",
    "* Cualquier correlación entre los residuos y los valores predichos violarían este supuesto.\n",
    "* Si los residuos muestran una patrón no lineal, como una relación curvilinea, el modelo esta especificado incorrectamente.\n",
    "\n",
    " **Corrección: ¿Qué hacer en caso de no-linealidad?**   \n",
    "\n",
    "* descartar observaciones influyentes\n",
    "* transformación de variables, ej: polinomial, logarítmica\n",
    "\n",
    "**Transformación logarítmica**: \n",
    "* utilizada para variables con un alto sesgo en su distribución \n",
    "* pondera crecientemente las diferencias entre los valores de la escala\n",
    "* caso típico: ingreso\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testeando linealidad: \n",
    "# Harvey-Collier multiplier test for Null hypothesis \n",
    "# that the linear specification is correct:\n",
    "from statsmodels.compat import lzip\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.api as sms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "name = [\"t value\", \"p value\"]\n",
    "test = sms.linear_harvey_collier(res)\n",
    "lzip(name, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimar normalidad de los residuos:\n",
    "# Jarque_Bera test\n",
    "name = [\"Jarque-Bera\", \"Chi^2 two-tail prob.\", \"Skew\", \"Kurtosis\"]\n",
    "test = sms.jarque_bera(results.resid)\n",
    "lzip(name, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Omni test\n",
    "name = [\"Chi^2\", \"Two-tail probability\"]\n",
    "test = sms.omni_normtest(results.resid)\n",
    "lzip(name, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " \n",
    "### 2. **Observaciones influyentes:**  \n",
    "   * Un *outlier* o valor atípico es una observación que es considerablemente distinta de la mayoría de los datos. Pueden ser causados por errores de registro/medición (en cuyo caso deben ser corregidos/removidos) o pueden ser casos que el modelo no explique bien pero que contengan información importante. \n",
    "   * Un punto con alto *leverage* (*apalancamiento*) es una observación que tiene un valor muy inusual (respecto al general de observaciones) en la variable explicativa.   \n",
    "   * Un punto *influyente* es una observación cuya presencia/ausencia genera un cambio importante en la estimación de los coeficientes de regresión. No todo outlier es una observación influyente, pero toda observación influyente es un outlier. \n",
    " \n",
    " **Detección de problemas:**  \n",
    "\n",
    " Identificando influyentes: Distancia de Cook\n",
    "Se trata de una diferencia de la predicción del modelo con y sin\n",
    "la observación , ponderada por el número de parametros en el\n",
    "modelo (p) y la media cuadrática del error (MSE).\n",
    "\n",
    "Se establece un punto de corte de $4/(n − k − 1)$, valores mayores\n",
    "se consideran influyentes -> outliers con alta capacidad de\n",
    "palanca.\n",
    "$$DCook =\\frac{\\sum{(\\hat{y_j} − \\hat{y_{j(i)}} )^2}}{p \\cdot MSE}$$\n",
    "\n",
    "\n",
    " **Corrección:**   \n",
    "\n",
    "* estimar Cook para todas las observaciones\n",
    "* detectar observaciones con Cook > punto de corte = influyentes\n",
    "* re-estimar modelo sin las observaciones y comparar resultados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de puntos influyentes\n",
    "fig = sm.graphics.influence_plot(res, criterion=\"cooks\")\n",
    "fig.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Clase OLSInfluence de statsmodels\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "\n",
    "test_class = OLSInfluence(results)\n",
    "test_class.dfbetas[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.regressionplots import plot_leverage_resid2\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "fig = plot_leverage_resid2(results, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3. Homoscedasticidad (homogeneidad de varianza de los residuos a lo largo de los valores predichos):\n",
    "Cuando hay heteroscedasticidad en los residuos, la estimación de los parámetros y su significancia estadística pueden verse afectada.\n",
    " \n",
    " **Detección de Heteroscedasticidad:**  \n",
    "\n",
    "* Mediante inspección visual de gráficos de XX contra XX\n",
    "\n",
    "* Usando test de White\n",
    "  \n",
    "* Usando test de Goldfeld-Quandt\n",
    "\n",
    "se contrasta la hipótesis nula de que la varianza del error es\n",
    "constante (=no diferencias), y la hipótesis alternativa de que\n",
    "el error de la varianza no es constante.\n",
    "por lo tanto, se busca no rechazar la hipótesis nula y valores\n",
    "p>0.05\n",
    "26\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.compat import lzip\n",
    "import statsmodels.stats.api as sms\n",
    "\n",
    "# Breusch-Pagan test\n",
    "name = [\"Lagrange multiplier statistic\", \"p-value\", \"f-value\", \"f p-value\"]\n",
    "test = sms.het_breuschpagan(results.resid, results.model.exog)\n",
    "lzip(name, test)\n",
    "\n",
    "Goldfeld-Quandt test\n",
    "name = [\"F statistic\", \"p-value\"]\n",
    "test = sms.het_goldfeldquandt(results.resid, results.model.exog)\n",
    "lzip(name, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " **Corrección de Heteroscedasticidad:**   \n",
    "Se corrige estimando un modelo de regresión que calcule los errores estándar robustos a heteroscedasticidad ()\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4. No multicolinealidad\n",
    "\n",
    "Para poder calcular los estimadores de mínimos cuadrados, se requiere que no exista una relación lineal exacta entre los regresores, es decir, que no existe *multicolinealidad perfecta*  en el modelo, o en otras palabras, que ningún predictor puede ser una combinación lineal de los otros predictores. En general, esto no suele presentarse en la práctica salvo que el modelo esté mal diseñado. Lo que sí es más frecuente es que haya una relación *aproximadamente lineal* entre los regresores, en cuyo caso los estimadores obtenidos serán en general poco precisos, pues se produce una inflación de los errores estándar. A esta situación se le llama * *multicolinealidad imperfecta*.\n",
    "\n",
    "\n",
    " **Detectando multicolinealidad:**  \n",
    "\n",
    "Variance Inflation Factor (VIF):  \n",
    "Teniendo un modelo multiple con $i$ variables explicativas, el VIF asociado a cada variable se calcula en base a un modelo donde $x_i$ es la variable de respuesta y las otras $x$ son las variables explicativas. Entonces, \n",
    "\n",
    "$$VIF_i  = \\frac{1}{1-{R_{x_i}}^2 }$$\n",
    "\n",
    "Mientras mayor es el ${R_{x_i}}^2$, más pequeño el denominador y más grande será el VIF, que indicará alta multicolinealidad para esa variable en ese modelo con $i$ variables predictoras. \n",
    "Si ${R_{x_i}}^2 =0 , VIF_i=1$, y no hay colinealidad. En general, se suele considerar problemático encontrar variables con VIF mayores a 5 (otros umbrales típicos son 2.5 y 10)\n",
    "\n",
    "**¿Cuándo es un problema y cuando no lo es?**\n",
    "\n",
    "La multicolinealidad es un problema solo para las variables que son colineales, ya que altera los errores estándar y hace a los coeficientes inestables en varias formas. Sin embargo, muchas otras características del modelo se mantienen, por lo cual hay varias situaciones donde un VIF alto no es algo muy problemático.\n",
    "\n",
    "* Cuando el modelo busca predecir y no explicar. Supongamos que ajustamos un modelo predictivo de alturas de un grupo de personas en función de otras variables: peso, longitud del brazo, longitud de la pierna, etc. con datos de entrenamiento para luego testearlo. La multicolinealidad en los datos de entrenamiento solo debería reducir el rendimiento predictivo en el conjunto de datos de prueba si la covarianza entre las variables en los datos de entrenamiento y los datos de prueba son diferentes. Si la estructura de covarianza (y, en consecuencia, la multicolinealidad) es similar en los datos de entrenamiento como los de prueba, entonces no representa un problema para la predicción. Y como los datos de prueba suelen ser un subconjunto aleatorio del dataset completo, generalmente es razonable suponer que la estructura de covarianza es la misma.\n",
    "En el mismo ejemplo de las alturas, es bien esperable que las variables explicativas que nombramos posiblemente estén fuertemente correlacionadas en el dataset de entrenamiento, pero si podemos asumir que la longitud de los brazos, la longitud de las piernas, el peso, etc. están correlacionados de manera similar en ambos dataset, no hay problema. \n",
    "\n",
    "* Cuando las variables colineales son usadas como controles y no son colineales con la variable de interes, ya que los coeficientes de esta última no son afectados, y los controles funcionan normalmente.\n",
    "* Cuando el VIF alto es causado por la inclusión de potencias o productos de otras variables (e.g. si incluimos la variable $edad$ y la variable $edad^2$), ya que por construcción podrían estar altamente correlacionadas. Una solución para disminuir la correlación es centrar las variables originales sobre el promedio antes de crear las potencias o productos (práctica usual, sobre todo al hacer modelos con interacciones). En cualquier caso, el p-value para estas variables creadas y el $R^2$ del modelo se mantienen iguales. \n",
    "* Cuando  The variables with high VIFs are indicator (dummy) variables that represent a categorical variable with three or more categories. If the proportion of cases in the reference category is small, the indicator variables will necessarily have high VIFs, even if the categorical variable is not associated with other variables in the regression model.\n",
    "\n",
    "\n",
    " **Corrección:**   \n",
    "* Eliminación de variables:\n",
    "\n",
    "* Aumentar el tamaño muestral\n",
    "  \n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Diagnostic Plots en statmodels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos un caso para el cual en statsmodels no están las funciones integradas en la librería, sino que se sigue un script en su página de documentación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple multiple linear regression\n",
    "\n",
    "Se cargan datos que vimos la semana pasada de ventas con respecto a publicidad en distintos medios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_url = \"https://raw.githubusercontent.com/nguyen-toan/ISLR/07fd968ea484b5f6febc7b392a28eb64329a4945/dataset/Advertising.csv\"\n",
    "df = pd.read_csv(data_url).drop('Unnamed: 0', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting linear model\n",
    "res = smf.ols(formula= \"Sales ~ TV + Radio + Newspaper\", data=df).fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagnostic Figures/Table\n",
    "\n",
    "Gráficos de Diagnóstico\n",
    "\n",
    "    a. residuos\n",
    "    b. qq\n",
    "    c. scale location\n",
    "    d. leverage\n",
    "\n",
    "y una tabla\n",
    "\n",
    "    a. vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base code\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from statsmodels.tools.tools import maybe_unwrap_results\n",
    "from statsmodels.graphics.gofplots import ProbPlot\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Type\n",
    "\n",
    "style_talk = 'seaborn-talk'    #refer to plt.style.available\n",
    "\n",
    "class Linear_Reg_Diagnostic():\n",
    "    \"\"\"\n",
    "    Diagnostic plots to identify potential problems in a linear regression fit.\n",
    "    Mainly,\n",
    "        a. non-linearity of data\n",
    "        b. Correlation of error terms\n",
    "        c. non-constant variance \n",
    "        d. outliers\n",
    "        e. high-leverage points\n",
    "        f. collinearity\n",
    "\n",
    "    Author:\n",
    "        Prajwal Kafle (p33ajkafle@gmail.com, where 3 = r)\n",
    "        Does not come with any sort of warranty. \n",
    "        Please test the code one your end before using.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 results: Type[statsmodels.regression.linear_model.RegressionResultsWrapper]) -> None:\n",
    "        \"\"\"\n",
    "        For a linear regression model, generates following diagnostic plots:\n",
    "\n",
    "        a. residual\n",
    "        b. qq\n",
    "        c. scale location and\n",
    "        d. leverage\n",
    "\n",
    "        and a table\n",
    "\n",
    "        e. vif\n",
    "\n",
    "        Args:\n",
    "            results (Type[statsmodels.regression.linear_model.RegressionResultsWrapper]): \n",
    "                must be instance of statsmodels.regression.linear_model object\n",
    "\n",
    "        Raises:\n",
    "            TypeError: if instance does not belong to above object\n",
    "\n",
    "        Example:\n",
    "        >>> import numpy as np\n",
    "        >>> import pandas as pd\n",
    "        >>> import statsmodels.formula.api as smf\n",
    "        >>> x = np.linspace(-np.pi, np.pi, 100)\n",
    "        >>> y = 3*x + 8 + np.random.normal(0,1, 100)\n",
    "        >>> df = pd.DataFrame({'x':x, 'y':y})\n",
    "        >>> res = smf.ols(formula= \"y ~ x\", data=df).fit()\n",
    "        >>> cls = Linear_Reg_Diagnostic(res)\n",
    "        >>> cls(plot_context=\"seaborn-paper\")     \n",
    "\n",
    "        In case you do not need all plots you can also independently make an individual plot/table\n",
    "        in following ways\n",
    "\n",
    "        >>> cls = Linear_Reg_Diagnostic(res)\n",
    "        >>> cls.residual_plot()\n",
    "        >>> cls.qq_plot()\n",
    "        >>> cls.scale_location_plot()\n",
    "        >>> cls.leverage_plot()\n",
    "        >>> cls.vif_table()\n",
    "        \"\"\"\n",
    "\n",
    "        if isinstance(results, statsmodels.regression.linear_model.RegressionResultsWrapper) is False:\n",
    "            raise TypeError(\"result must be instance of statsmodels.regression.linear_model.RegressionResultsWrapper object\")\n",
    "\n",
    "        self.results = maybe_unwrap_results(results)\n",
    "\n",
    "        self.y_true = self.results.model.endog\n",
    "        self.y_predict = self.results.fittedvalues\n",
    "        self.xvar = self.results.model.exog\n",
    "        self.xvar_names = self.results.model.exog_names\n",
    "\n",
    "        self.residual = np.array(self.results.resid)\n",
    "        influence = self.results.get_influence()\n",
    "        self.residual_norm = influence.resid_studentized_internal\n",
    "        self.leverage = influence.hat_matrix_diag\n",
    "        self.cooks_distance = influence.cooks_distance[0]\n",
    "        self.nparams = len(self.results.params)\n",
    "\n",
    "    def __call__(self, plot_context='seaborn-paper'):\n",
    "        # print(plt.style.available)\n",
    "        with plt.style.context(plot_context):\n",
    "            fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(10,10))\n",
    "            self.residual_plot(ax=ax[0,0])\n",
    "            self.qq_plot(ax=ax[0,1])\n",
    "            self.scale_location_plot(ax=ax[1,0])\n",
    "            self.leverage_plot(ax=ax[1,1])\n",
    "            plt.show()\n",
    "        \n",
    "        self.vif_table()\n",
    "        return fig, ax\n",
    "\n",
    "\n",
    "    def residual_plot(self, ax=None):\n",
    "        \"\"\"\n",
    "        Residual vs Fitted Plot\n",
    "\n",
    "        Graphical tool to identify non-linearity.\n",
    "        (Roughly) Horizontal red line is an indicator that the residual has a linear pattern\n",
    "        \"\"\"\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "        sns.residplot(\n",
    "            x=self.y_predict, \n",
    "            y=self.residual, \n",
    "            lowess=True,\n",
    "            scatter_kws={'alpha': 0.5},\n",
    "            line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8}, \n",
    "            ax=ax)\n",
    "\n",
    "        # annotations\n",
    "        residual_abs = np.abs(self.residual)\n",
    "        abs_resid = np.flip(np.sort(residual_abs))\n",
    "        abs_resid_top_3 = abs_resid[:3]\n",
    "        for i, _ in enumerate(abs_resid_top_3):\n",
    "            ax.annotate(\n",
    "                i, \n",
    "                xy=(self.y_predict[i], self.residual[i]), \n",
    "                color='C3')\n",
    "\n",
    "        ax.set_title('Residuals vs Fitted', fontweight=\"bold\")\n",
    "        ax.set_xlabel('Fitted values')\n",
    "        ax.set_ylabel('Residuals')\n",
    "        return ax\n",
    "\n",
    "    def qq_plot(self, ax=None):\n",
    "        \"\"\"\n",
    "        Standarized Residual vs Theoretical Quantile plot\n",
    "\n",
    "        Used to visually check if residuals are normally distributed.\n",
    "        Points spread along the diagonal line will suggest so.\n",
    "        \"\"\"\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "        \n",
    "        QQ = ProbPlot(self.residual_norm)\n",
    "        QQ.qqplot(line='45', alpha=0.5, lw=1, ax=ax)\n",
    "\n",
    "        # annotations\n",
    "        abs_norm_resid = np.flip(np.argsort(np.abs(self.residual_norm)), 0)\n",
    "        abs_norm_resid_top_3 = abs_norm_resid[:3]\n",
    "        for r, i in enumerate(abs_norm_resid_top_3):\n",
    "            ax.annotate(\n",
    "                i, \n",
    "                xy=(np.flip(QQ.theoretical_quantiles, 0)[r], self.residual_norm[i]), \n",
    "                ha='right', color='C3')\n",
    "\n",
    "        ax.set_title('Normal Q-Q', fontweight=\"bold\")\n",
    "        ax.set_xlabel('Theoretical Quantiles')\n",
    "        ax.set_ylabel('Standardized Residuals')\n",
    "        return ax\n",
    "  \n",
    "    def scale_location_plot(self, ax=None):\n",
    "        \"\"\"\n",
    "        Sqrt(Standarized Residual) vs Fitted values plot\n",
    "\n",
    "        Used to check homoscedasticity of the residuals.\n",
    "        Horizontal line will suggest so.\n",
    "        \"\"\"\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "        residual_norm_abs_sqrt = np.sqrt(np.abs(self.residual_norm))\n",
    "\n",
    "        ax.scatter(self.y_predict, residual_norm_abs_sqrt, alpha=0.5);\n",
    "        sns.regplot(\n",
    "            x=self.y_predict, \n",
    "            y=residual_norm_abs_sqrt,\n",
    "            scatter=False, ci=False,\n",
    "            lowess=True,\n",
    "            line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8}, \n",
    "            ax=ax)\n",
    "\n",
    "        # annotations\n",
    "        abs_sq_norm_resid = np.flip(np.argsort(residual_norm_abs_sqrt), 0)\n",
    "        abs_sq_norm_resid_top_3 = abs_sq_norm_resid[:3]\n",
    "        for i in abs_sq_norm_resid_top_3:\n",
    "            ax.annotate(\n",
    "                i, \n",
    "                xy=(self.y_predict[i], residual_norm_abs_sqrt[i]), \n",
    "                color='C3')\n",
    "        ax.set_title('Scale-Location', fontweight=\"bold\")\n",
    "        ax.set_xlabel('Fitted values')\n",
    "        ax.set_ylabel(r'$\\sqrt{|\\mathrm{Standardized\\ Residuals}|}$');\n",
    "        return ax\n",
    "\n",
    "    def leverage_plot(self, ax=None):\n",
    "        \"\"\"\n",
    "        Residual vs Leverage plot\n",
    "\n",
    "        Points falling outside Cook's distance curves are considered observation that can sway the fit\n",
    "        aka are influential.\n",
    "        Good to have none outside the curves.\n",
    "        \"\"\"\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "        ax.scatter(\n",
    "            self.leverage, \n",
    "            self.residual_norm, \n",
    "            alpha=0.5);\n",
    "        \n",
    "        sns.regplot(\n",
    "            x=self.leverage, \n",
    "            y=self.residual_norm,\n",
    "            scatter=False,\n",
    "            ci=False,\n",
    "            lowess=True,\n",
    "            line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8},\n",
    "            ax=ax)\n",
    "\n",
    "        # annotations\n",
    "        leverage_top_3 = np.flip(np.argsort(self.cooks_distance), 0)[:3]\n",
    "        for i in leverage_top_3:\n",
    "            ax.annotate(\n",
    "                i, \n",
    "                xy=(self.leverage[i], self.residual_norm[i]),\n",
    "                color = 'C3')\n",
    "\n",
    "        xtemp, ytemp = self.__cooks_dist_line(0.5) # 0.5 line\n",
    "        ax.plot(xtemp, ytemp, label=\"Cook's distance\", lw=1, ls='--', color='red')\n",
    "        xtemp, ytemp = self.__cooks_dist_line(1) # 1 line\n",
    "        ax.plot(xtemp, ytemp, lw=1, ls='--', color='red')\n",
    "        \n",
    "        ax.set_xlim(0, max(self.leverage)+0.01)\n",
    "        ax.set_title('Residuals vs Leverage', fontweight=\"bold\")\n",
    "        ax.set_xlabel('Leverage')\n",
    "        ax.set_ylabel('Standardized Residuals')\n",
    "        ax.legend(loc='upper right')\n",
    "        return ax\n",
    "\n",
    "    def vif_table(self):\n",
    "        \"\"\"\n",
    "        VIF table\n",
    "\n",
    "        VIF, the variance inflation factor, is a measure of multicollinearity.\n",
    "        VIF > 5 for a variable indicates that it is highly collinear with the \n",
    "        other input variables.\n",
    "        \"\"\"\n",
    "        vif_df = pd.DataFrame()\n",
    "        vif_df[\"Features\"] = self.xvar_names\n",
    "        vif_df[\"VIF Factor\"] = [variance_inflation_factor(self.xvar, i) for i in range(self.xvar.shape[1])]\n",
    "\n",
    "        print(vif_df\n",
    "                .sort_values(\"VIF Factor\")\n",
    "                .round(2))\n",
    "        \n",
    "\n",
    "    def __cooks_dist_line(self, factor):\n",
    "        \"\"\"\n",
    "        Helper function for plotting Cook's distance curves\n",
    "        \"\"\"\n",
    "        p = self.nparams \n",
    "        formula = lambda x: np.sqrt((factor * p * (1 - x)) / x)\n",
    "        x = np.linspace(0.001, max(self.leverage), 50)\n",
    "        y = formula(x)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haciendo uso de\n",
    "\n",
    "    * fitted model en los datos de Advertising \n",
    "    * el codigo base\n",
    "generamos diagnostic plots uno por uno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = Linear_Reg_Diagnostic(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A. Residual vs Fitted values**\n",
    "\n",
    "Para identificar no-linealidad.\n",
    "\n",
    "En el gráfico, la línea más o menos horizontal es un indicador que los residuos tienen un patrón lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls.residual_plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B. Standarized Residual vs Theoretical Quantile**\n",
    "\n",
    "Esto es para chequear visualmente si los residuos están distribuidos normal.\n",
    "\n",
    "la dispersión sobre la línea diagonal nos sugiere que sí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls.qq_plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C. Sqrt(Standarized Residual) vs Fitted values**\n",
    "\n",
    "Este gráfico es para chequear homoscedasticidad de los residuos.\n",
    "\n",
    "Una línea casi horizontal roja en el gráfico lo sugeriría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls.scale_location_plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D. Residual vs Leverage**\n",
    "\n",
    "Los puntos que caen fuera de las curvas de distancia de Cook curves son considerados observaciones que serían influyentes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls.leverage_plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E. VIF**\n",
    "\n",
    "El variance inflation factor (VIF), es una medida de multicolinealidad.\n",
    "\n",
    "VIF > 5 para una variable indica que es altamente colineal con las otras variables explicativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls.vif_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, all diagnostics can be generated in one go as follows.\n",
    "# Fig and ax can be used to modify axes or plot properties after the fact.\n",
    "cls = Linear_Reg_Diagnostic(res)\n",
    "fig, ax = cls()\n",
    "\n",
    "#fig.savefig('../../docs/source/_static/images/linear_regression_diagnostics_plots.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## “TODOS LOS MODELOS ESTÁN MAL, PERO ALGUNOS SON ÚTILES” -GEORGE E.P. BOX\n",
    "La verdad es que ningún modelo es perfecto. Sin embargo, incluso los modelos imperfectos pueden ser útiles. Informar sobre un modelo defectuoso puede ser razonable siempre que seamos claros e informemos las deficiencias del modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
