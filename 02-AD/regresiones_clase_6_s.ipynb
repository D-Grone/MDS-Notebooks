{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c934f1ed",
   "metadata": {},
   "source": [
    "# Análisis y limpieza de datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261ff363",
   "metadata": {},
   "source": [
    "# Modelos de regresión lineal en Python\n",
    "\n",
    "Dos de las implementaciones de modelos de regresión lineal más utilizadas en Python son: `scikit-learn` y `statsmodels`. Aunque ambas están muy optimizadas, `Scikit-learn` está orientada principalmente a la predicción, por lo que no dispone de apenas funcionalidades que muestren las muchas características del modelo que se deben analizar para hacer inferencia. [`statsmodels`](https://www.statsmodels.org/stable/index.html) es mucho más completo en este sentido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1188f3d0",
   "metadata": {},
   "source": [
    "# Ejemplo regresión lineal simple\n",
    "\n",
    "\n",
    "Supóngase que un analista de deportes quiere saber si existe una relación entre el número de veces que batean los jugadores de un equipo de béisbol y el número de runs que consigue. En caso de existir y de establecer un modelo, podría predecir el resultado del partido\n",
    "\n",
    "# Librerías\n",
    "\n",
    "\n",
    "Las librerías utilizadas en este ejemplo son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf5813c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Gráficos\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocesado y modelado\n",
    "# ==============================================================================\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Configuración matplotlib\n",
    "# ==============================================================================\n",
    "plt.rcParams['image.cmap'] = \"bwr\"\n",
    "#plt.rcParams['figure.dpi'] = \"100\"\n",
    "plt.rcParams['savefig.bbox'] = \"tight\"\n",
    "style.use('ggplot') or plt.style.use('ggplot')\n",
    "\n",
    "# Configuración warnings\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fbbe1d",
   "metadata": {},
   "source": [
    "# Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb81cce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>equipos</th>\n",
       "      <th>bateos</th>\n",
       "      <th>runs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Texas</td>\n",
       "      <td>5659</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boston</td>\n",
       "      <td>5710</td>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Detroit</td>\n",
       "      <td>5563</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   equipos  bateos  runs\n",
       "0    Texas    5659   855\n",
       "1   Boston    5710   875\n",
       "2  Detroit    5563   787"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datos\n",
    "# ==============================================================================\n",
    "equipos = [\"Texas\",\"Boston\",\"Detroit\",\"Kansas\",\"St.\",\"New_S.\",\"New_Y.\",\n",
    "           \"Milwaukee\",\"Colorado\",\"Houston\",\"Baltimore\",\"Los_An.\",\"Chicago\",\n",
    "           \"Cincinnati\",\"Los_P.\",\"Philadelphia\",\"Chicago\",\"Cleveland\",\"Arizona\",\n",
    "           \"Toronto\",\"Minnesota\",\"Florida\",\"Pittsburgh\",\"Oakland\",\"Tampa\",\n",
    "           \"Atlanta\",\"Washington\",\"San.F\",\"San.I\",\"Seattle\"]\n",
    "bateos = [5659,  5710, 5563, 5672, 5532, 5600, 5518, 5447, 5544, 5598,\n",
    "          5585, 5436, 5549, 5612, 5513, 5579, 5502, 5509, 5421, 5559,\n",
    "          5487, 5508, 5421, 5452, 5436, 5528, 5441, 5486, 5417, 5421]\n",
    "\n",
    "runs = [855, 875, 787, 730, 762, 718, 867, 721, 735, 615, 708, 644, 654, 735,\n",
    "        667, 713, 654, 704, 731, 743, 619, 625, 610, 645, 707, 641, 624, 570,\n",
    "        593, 556]\n",
    "\n",
    "datos = pd.DataFrame({'equipos': equipos, 'bateos': bateos, 'runs': runs})\n",
    "datos.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa89d4a",
   "metadata": {},
   "source": [
    "# Representación gráfica\n",
    "\n",
    "\n",
    "El primer paso antes de generar un modelo de regresión simple es representar los datos para poder intuir si existe una relación y cuantificar dicha relación mediante un coeficiente de correlación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63ff2764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x276.48 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gráfico\n",
    "# ==============================================================================\n",
    "fig, ax = plt.subplots(figsize=(6, 3.84))\n",
    "\n",
    "\n",
    "datos.plot(\n",
    "    x    = 'bateos',\n",
    "    y    = 'runs',\n",
    "    c    = 'firebrick',\n",
    "    kind = \"scatter\",\n",
    "    ax   = ax\n",
    ")\n",
    "ax.set_title('Distribución de bateos y runs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb015284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficiente de correlación de Pearson:  0.6106270467206687\n",
      "P-value:  0.0003388351359791978\n"
     ]
    }
   ],
   "source": [
    "# Correlación lineal entre las dos variables\n",
    "# ==============================================================================\n",
    "corr_test = pearsonr(x = datos['bateos'], y =  datos['runs'])\n",
    "print(\"Coeficiente de correlación de Pearson: \", corr_test[0])\n",
    "print(\"P-value: \", corr_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f747265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "334b52b6",
   "metadata": {},
   "source": [
    "El gráfico y el test de correlación muestran una relación lineal, de intensidad considerable (r = 0.61) y significativa (p-value = 0.000339). Tiene sentido intentar generar un modelo de regresión lineal con el objetivo de predecir el número de runs en función del número de bateos del equipo.\n",
    "\n",
    "La regla de \"dedo pulgar\" para el valor-p. es que $p-value<0.01$. Sin embargo, también se acepta en ciertas circunstancias un $p-value< 0.05$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958f9c9a",
   "metadata": {},
   "source": [
    "# Ajuste del modelo\n",
    "\n",
    "\n",
    "Se ajusta un modelo empleando como variable respuesta runs y como predictor bateos. Como en todo estudio predictivo, no solo es importante ajustar el modelo, sino también cuantificar su capacidad para predecir nuevas observaciones. Para poder hacer esta evaluación, se dividen los datos en dos grupos, uno de entrenamiento y otro de test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea606e91",
   "metadata": {},
   "source": [
    "### Scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f84f54",
   "metadata": {},
   "source": [
    "Tratando de remodelar con (-1, 1). Hemos proporcionado la columna como 1 pero las filas como desconocidas (-1). Entonces obtenemos el resultado de una nueva forma como (n, 1) (Compatible con la forma original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed8a318c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# División de los datos en train y test\n",
    "# ==============================================================================\n",
    "X = datos[['bateos']]\n",
    "y = datos['runs']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                        X.values.reshape(-1,1),\n",
    "                                        y.values.reshape(-1,1),\n",
    "                                        train_size   = 0.8,\n",
    "                                        random_state = 1234,# OJO!\n",
    "                                        shuffle      = True# barajar antes de muestrear\n",
    "                                    )\n",
    "# Creación del modelo\n",
    "# ==============================================================================\n",
    "modelo = LinearRegression()\n",
    "modelo.fit(X = X_train.reshape(-1, 1), y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e8896e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f47f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d52c51a6",
   "metadata": {},
   "source": [
    "La función `zip()` toma iterables (pueden ser cero o más), los agrega en una tupla y los devuelve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c68e4cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: [-2367.7028413]\n",
      "Coeficiente: [('bateos', 0.5528713534479736)]\n",
      "Coeficiente de determinación R^2: 0.3586119899498744\n"
     ]
    }
   ],
   "source": [
    "# Información del modelo\n",
    "# ==============================================================================\n",
    "print(\"Intercept:\", modelo.intercept_)\n",
    "print(\"Coeficiente:\", list(zip(X.columns, modelo.coef_.flatten(), )))# flatten: Aplana la salida en una dimension. \n",
    "print(\"Coeficiente de determinación R^2:\", modelo.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187e6532",
   "metadata": {},
   "source": [
    "Una vez entrenado el modelo, se evalúa la capacidad predictiva empleando el conjunto de test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "004ed963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(643.7874209289012, 721), (720.0836677047214, 708), (690.7814859719788, 762)]\n",
      "\n",
      "El error (rmse) de test es: 59.336716083360486\n"
     ]
    }
   ],
   "source": [
    "# Error de test del modelo \n",
    "# ==============================================================================\n",
    "predicciones = modelo.predict(X = X_test)\n",
    "print(list(zip(predicciones[0:3,].flatten(),y_test.flatten())))\n",
    "\n",
    "rmse = mean_squared_error(\n",
    "        y_true  = y_test,\n",
    "        y_pred  = predicciones,\n",
    "        squared = False\n",
    "       )\n",
    "print(\"\")\n",
    "print(f\"El error (rmse) de test es: {rmse}\")# error cuadratico medio tiene sentido solo para dos modelos distintos para los mismos datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef48e3d",
   "metadata": {},
   "source": [
    "# Statsmodels\n",
    "La implementación de regresión lineal de Statsmodels, es más completa que la de `Scikitlearn` ya que, además de ajustar el modelo, permite calcular los test estadísticos y análisis necesarios para verificar que se cumplen las condiciones sobre las que se basa este tipo de modelos. Statsmodels tiene dos formas de entrenar el modelo:\n",
    "\n",
    "Indicando la fórmula del modelo y pasando los datos de entrenamiento como un dataframe que incluye la variable respuesta y los predictores. Esta forma es similar a la utilizada en R.\n",
    "\n",
    "Pasar dos matrices, una con los predictores y otra con la variable respuesta. Esta es igual a la empleada por Scikitlearn con la diferencia de que a la matriz de predictores hay que añadirle una primera columna de 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6986bfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# División de los datos en train y test\n",
    "# ==============================================================================\n",
    "X = datos[['bateos']]\n",
    "y = datos['runs']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                        X.values.reshape(-1,1),\n",
    "                                        y.values.reshape(-1,1),\n",
    "                                        train_size   = 0.8,\n",
    "                                        random_state = 1234,\n",
    "                                        shuffle      = True\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168e428c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b2f884c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creación del modelo utilizando el modo fórmula (similar a R)\n",
    "# # ==============================================================================\n",
    "# datos_train = pd.DataFrame(np.hstack((X_train, y_train)), columns=['bateos', 'runs'])\n",
    "# modelo = smf.ols(formula = 'runs ~bateos', data = datos_train)\n",
    "# modelo = modelo.fit()\n",
    "# print(modelo.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79580a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15cf9c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación del modelo utilizando matrices como en scikitlearn\n",
    "# ==============================================================================\n",
    "# A la matriz de predictores se le tiene que añadir una columna de 1s para el intercept del modelo\n",
    "X_train = sm.add_constant(X_train, prepend=True)#prepend constante primera columna\n",
    "\n",
    "modelo = sm.OLS(endog=y_train, exog=X_train,)\n",
    "\n",
    "modelo = modelo.fit()#cov_type='HC3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a94ff615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.271\n",
      "Model:                            OLS   Adj. R-squared:                  0.238\n",
      "Method:                 Least Squares   F-statistic:                     8.191\n",
      "Date:                Thu, 13 Oct 2022   Prob (F-statistic):            0.00906\n",
      "Time:                        20:09:47   Log-Likelihood:                -134.71\n",
      "No. Observations:                  24   AIC:                             273.4\n",
      "Df Residuals:                      22   BIC:                             275.8\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const      -2367.7028   1066.357     -2.220      0.037   -4579.192    -156.214\n",
      "x1             0.5529      0.193      2.862      0.009       0.152       0.953\n",
      "==============================================================================\n",
      "Omnibus:                        5.033   Durbin-Watson:                   1.902\n",
      "Prob(Omnibus):                  0.081   Jarque-Bera (JB):                3.170\n",
      "Skew:                           0.829   Prob(JB):                        0.205\n",
      "Kurtosis:                       3.650   Cond. No.                     4.17e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.17e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print(modelo.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56bc8a4",
   "metadata": {},
   "source": [
    "- Log-Likelihood: El valor logarítmico de verosimilitud es una medida de bondad de ajuste para cualquier modelo. Cuanto mayor sea el valor, mejor es el modelo.\n",
    "Debemos recordar que Log Likelihood puede estar entre -Inf y + Inf. Por lo tanto, la mirada absoluta al valor no puede dar ninguna indicación. Solo podemos comparar los valores de logaritmo de verosimilitud entre varios modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7317152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELO RANDOM\n",
    "# Creación del modelo utilizando matrices como en scikitlearn\n",
    "# ==============================================================================\n",
    "# A la matriz de predictores se le tiene que añadir una columna de 1s para el intercept del modelo\n",
    "# X_train = sm.add_constant(X_train, prepend=True)#prepend constante primera columna\n",
    "# dumb=np.full((len(y_train), 1), 1.)\n",
    "\n",
    "randnums= np.random.randint(1,100001,len(y_train))\n",
    "randnums= sm.add_constant(randnums, prepend=True)#prepend: constante primera columna\n",
    "\n",
    "modelo_rand = sm.OLS(endog=y_train, exog=randnums,)\n",
    "modelo_rand = modelo_rand.fit()#cov_type='HC3'\n",
    "print(modelo_rand.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acccde3",
   "metadata": {},
   "source": [
    "# Intervalos de confianza de los coeficientes¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8db5d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intervalos de confianza para los coeficientes del modelo\n",
    "# ==============================================================================\n",
    "modelo.conf_int(alpha=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9efaeb3",
   "metadata": {},
   "source": [
    "# Predicciones\n",
    "\n",
    "\n",
    "Una vez entrenado el modelo, se pueden obtener predicciones para nuevos datos. Los modelos de statsmodels permiten calcular las predicciones de dos formas:\n",
    "\n",
    "- `.predict()`: devuelve únicamente el valor de las predicciones.\n",
    "\n",
    "- `.get_prediction().summary_frame()`: devuelve, además de las predicciones, los intervalos de confianza asociados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c8264c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones con intervalo de confianza del 95%\n",
    "# ==============================================================================\n",
    "predicciones = modelo.get_prediction(exog = X_train).summary_frame(alpha=0.05)\n",
    "predicciones.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511326a0",
   "metadata": {},
   "source": [
    "# Representación gráfica del modelo\n",
    "\n",
    "\n",
    "Además de la línea de mínimos cuadrados, es recomendable incluir los límites superior e inferior del intervalo de confianza. Esto permite identificar la región en la que, según el modelo generado y para un determinado nivel de confianza, se encuentra el valor promedio de la variable respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaa4741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones con intervalo de confianza del 95%\n",
    "# ==============================================================================\n",
    "predicciones = modelo.get_prediction(exog = X_train).summary_frame(alpha=0.05)\n",
    "predicciones['x'] = X_train[:, 1]\n",
    "predicciones['y'] = y_train\n",
    "predicciones = predicciones.sort_values('x')\n",
    "\n",
    "# Gráfico del modelo\n",
    "# ==============================================================================\n",
    "fig, ax = plt.subplots(figsize=(6, 3.84))\n",
    "\n",
    "ax.scatter(predicciones['x'], predicciones['y'], marker='o', color = \"gray\")\n",
    "ax.plot(predicciones['x'], predicciones[\"mean\"], linestyle='-', label=\"OLS\")\n",
    "ax.plot(predicciones['x'], predicciones[\"mean_ci_lower\"], linestyle='--', color='red', label=\"95% CI\")\n",
    "ax.plot(predicciones['x'], predicciones[\"mean_ci_upper\"], linestyle='--', color='red')\n",
    "ax.fill_between(predicciones['x'], predicciones[\"mean_ci_lower\"], predicciones[\"mean_ci_upper\"], alpha=0.2)\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0adef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e908c87a",
   "metadata": {},
   "source": [
    "# Error de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85430a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error de test del modelo \n",
    "# ==============================================================================\n",
    "X_test = sm.add_constant(X_test, prepend=True)\n",
    "predicciones = modelo.predict(exog = X_test)\n",
    "\n",
    "\n",
    "rmse = mean_squared_error(\n",
    "        y_true  = y_test,\n",
    "        y_pred  = predicciones,\n",
    "        squared = False\n",
    "       )\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(f\"El error (rmse) de test es: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cd620d",
   "metadata": {},
   "source": [
    "# Interpretación\n",
    "La columna (coef) devuelve el valor estimado para los dos parámetros de la ecuación del modelo lineal ( $\\beta_0$  y  $\\beta_1$) que equivalen a la ordenada en el origen (intercept o const) y a la pendiente. Se muestran también los errores estándar, el valor del estadístico $t$ y el p-value (dos colas) de cada uno de los dos parámetros. Esto permite determinar si los predictores son significativamente distintos de 0, es decir, que tienen importancia en el modelo. Para el modelo generado, tanto la ordenada en el origen como la pendiente son significativas (p-values < 0.05).\n",
    "\n",
    "El valor de R-squared indica que el modelo es capaz de explicar el 27.1% de la variabilidad observada en la variable respuesta (runs). Además, el p-value obtenido en el test F (Prob (F-statistic) = 0.00906) indica que sí hay evidencias de que la varianza explicada por el modelo es superior a la esperada por azar (varianza total).\n",
    "\n",
    "El modelo lineal generado sigue la ecuación:\n",
    "\n",
    "- $runs = -2367.7028 + 0.6305 bateos$\n",
    "\n",
    "(la cte siempre tiene una interpretación, pero es Útil solo cuando hay datos en torno al cero, ningun partido tiene cerca de cero bateos (las regresiones son buenas para intrapolar no extrapolar)\n",
    " \n",
    "Por cada unidad que se incrementa el número de bateos, el número de runs aumenta en promedio 0.6305 unidades.\n",
    "\n",
    "El error de test del modelo es de 59.34. Las predicciones del modelo final se alejan en promedio 59.34 unidades del valor real.\n",
    "\n",
    "**Nota: Las unidades de medida de las ecuaciones se deben conservar!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c893c56a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88f842aa",
   "metadata": {},
   "source": [
    "# Ejemplo regresión lineal múltiple\n",
    "\n",
    "\n",
    "Supóngase que el departamento de ventas de una empresa quiere estudiar la influencia que tiene la publicidad a través de distintos canales sobre el número de ventas de un producto. Se dispone de un conjunto de datos que contiene los ingresos (en millones) conseguido por ventas en 200 regiones, así como la cantidad de presupuesto, también en millones, destinado a anuncios por radio, TV y periódicos en cada una de ellas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5e1fd9",
   "metadata": {},
   "source": [
    "# Librerías\n",
    "\n",
    "\n",
    "Las librerías utilizadas en este ejemplo son:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c03e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Gráficos\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocesado y modelado\n",
    "# ==============================================================================\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from scipy import stats\n",
    "\n",
    "# Configuración matplotlib\n",
    "# ==============================================================================\n",
    "plt.rcParams['image.cmap'] = \"bwr\"\n",
    "#plt.rcParams['figure.dpi'] = \"100\"\n",
    "plt.rcParams['savefig.bbox'] = \"tight\"\n",
    "style.use('ggplot') or plt.style.use('ggplot')\n",
    "\n",
    "# Configuración warnings\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3f651d",
   "metadata": {},
   "source": [
    "# Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de9306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos\n",
    "# ==============================================================================\n",
    "tv = [230.1, 44.5, 17.2, 151.5, 180.8, 8.7, 57.5, 120.2, 8.6, 199.8, 66.1, 214.7,\n",
    "      23.8, 97.5, 204.1, 195.4, 67.8, 281.4, 69.2, 147.3, 218.4, 237.4, 13.2,\n",
    "      228.3, 62.3, 262.9, 142.9, 240.1, 248.8, 70.6, 292.9, 112.9, 97.2, 265.6,\n",
    "      95.7, 290.7, 266.9, 74.7, 43.1, 228.0, 202.5, 177.0, 293.6, 206.9, 25.1,\n",
    "      175.1, 89.7, 239.9, 227.2, 66.9, 199.8, 100.4, 216.4, 182.6, 262.7, 198.9,\n",
    "      7.3, 136.2, 210.8, 210.7, 53.5, 261.3, 239.3, 102.7, 131.1, 69.0, 31.5,\n",
    "      139.3, 237.4, 216.8, 199.1, 109.8, 26.8, 129.4, 213.4, 16.9, 27.5, 120.5,\n",
    "      5.4, 116.0, 76.4, 239.8, 75.3, 68.4, 213.5, 193.2, 76.3, 110.7, 88.3, 109.8,\n",
    "      134.3, 28.6, 217.7, 250.9, 107.4, 163.3, 197.6, 184.9, 289.7, 135.2, 222.4,\n",
    "      296.4, 280.2, 187.9, 238.2, 137.9, 25.0, 90.4, 13.1, 255.4, 225.8, 241.7, 175.7,\n",
    "      209.6, 78.2, 75.1, 139.2, 76.4, 125.7, 19.4, 141.3, 18.8, 224.0, 123.1, 229.5,\n",
    "      87.2, 7.8, 80.2, 220.3, 59.6, 0.7, 265.2, 8.4, 219.8, 36.9, 48.3, 25.6, 273.7,\n",
    "      43.0, 184.9, 73.4, 193.7, 220.5, 104.6, 96.2, 140.3, 240.1, 243.2, 38.0, 44.7,\n",
    "      280.7, 121.0, 197.6, 171.3, 187.8, 4.1, 93.9, 149.8, 11.7, 131.7, 172.5, 85.7,\n",
    "      188.4, 163.5, 117.2, 234.5, 17.9, 206.8, 215.4, 284.3, 50.0, 164.5, 19.6, 168.4,\n",
    "      222.4, 276.9, 248.4, 170.2, 276.7, 165.6, 156.6, 218.5, 56.2, 287.6, 253.8, 205.0,\n",
    "      139.5, 191.1, 286.0, 18.7, 39.5, 75.5, 17.2, 166.8, 149.7, 38.2, 94.2, 177.0,\n",
    "      283.6, 232.1]\n",
    "\n",
    "radio = [37.8, 39.3, 45.9, 41.3, 10.8, 48.9, 32.8, 19.6, 2.1, 2.6, 5.8, 24.0, 35.1,\n",
    "         7.6, 32.9, 47.7, 36.6, 39.6, 20.5, 23.9, 27.7, 5.1, 15.9, 16.9, 12.6, 3.5,\n",
    "         29.3, 16.7, 27.1, 16.0, 28.3, 17.4, 1.5, 20.0, 1.4, 4.1, 43.8, 49.4, 26.7,\n",
    "         37.7, 22.3, 33.4, 27.7, 8.4, 25.7, 22.5, 9.9, 41.5, 15.8, 11.7, 3.1, 9.6,\n",
    "         41.7, 46.2, 28.8, 49.4, 28.1, 19.2, 49.6, 29.5, 2.0, 42.7, 15.5, 29.6, 42.8,\n",
    "         9.3, 24.6, 14.5, 27.5, 43.9, 30.6, 14.3, 33.0, 5.7, 24.6, 43.7, 1.6, 28.5,\n",
    "         29.9, 7.7, 26.7, 4.1, 20.3, 44.5, 43.0, 18.4, 27.5, 40.6, 25.5, 47.8, 4.9,\n",
    "         1.5, 33.5, 36.5, 14.0, 31.6, 3.5, 21.0, 42.3, 41.7, 4.3, 36.3, 10.1, 17.2,\n",
    "         34.3, 46.4, 11.0, 0.3, 0.4, 26.9, 8.2, 38.0, 15.4, 20.6, 46.8, 35.0, 14.3,\n",
    "         0.8, 36.9, 16.0, 26.8, 21.7, 2.4, 34.6, 32.3, 11.8, 38.9, 0.0, 49.0, 12.0,\n",
    "         39.6, 2.9, 27.2, 33.5, 38.6, 47.0, 39.0, 28.9, 25.9, 43.9, 17.0, 35.4, 33.2,\n",
    "         5.7, 14.8, 1.9, 7.3, 49.0, 40.3, 25.8, 13.9, 8.4, 23.3, 39.7, 21.1, 11.6, 43.5,\n",
    "         1.3, 36.9, 18.4, 18.1, 35.8, 18.1, 36.8, 14.7, 3.4, 37.6, 5.2, 23.6, 10.6, 11.6,\n",
    "         20.9, 20.1, 7.1, 3.4, 48.9, 30.2, 7.8, 2.3, 10.0, 2.6, 5.4, 5.7, 43.0, 21.3, 45.1,\n",
    "         2.1, 28.7, 13.9, 12.1, 41.1, 10.8, 4.1, 42.0, 35.6, 3.7, 4.9, 9.3, 42.0, 8.6]\n",
    "\n",
    "periodico = [69.2, 45.1, 69.3, 58.5, 58.4, 75.0, 23.5, 11.6, 1.0, 21.2, 24.2, 4.0,\n",
    "             65.9, 7.2, 46.0, 52.9, 114.0, 55.8, 18.3, 19.1, 53.4, 23.5, 49.6, 26.2,\n",
    "             18.3, 19.5, 12.6, 22.9, 22.9, 40.8, 43.2, 38.6, 30.0, 0.3, 7.4, 8.5, 5.0,\n",
    "             45.7, 35.1, 32.0, 31.6, 38.7, 1.8, 26.4, 43.3, 31.5, 35.7, 18.5, 49.9,\n",
    "             36.8, 34.6, 3.6, 39.6, 58.7, 15.9, 60.0, 41.4, 16.6, 37.7, 9.3, 21.4, 54.7,\n",
    "             27.3, 8.4, 28.9, 0.9, 2.2, 10.2, 11.0, 27.2, 38.7, 31.7, 19.3, 31.3, 13.1,\n",
    "             89.4, 20.7, 14.2, 9.4, 23.1, 22.3, 36.9, 32.5, 35.6, 33.8, 65.7, 16.0, 63.2,\n",
    "             73.4, 51.4, 9.3, 33.0, 59.0, 72.3, 10.9, 52.9, 5.9, 22.0, 51.2, 45.9, 49.8,\n",
    "             100.9, 21.4, 17.9, 5.3, 59.0, 29.7, 23.2, 25.6, 5.5, 56.5, 23.2, 2.4, 10.7,\n",
    "             34.5, 52.7, 25.6, 14.8, 79.2, 22.3, 46.2, 50.4, 15.6, 12.4, 74.2, 25.9, 50.6,\n",
    "             9.2, 3.2, 43.1, 8.7, 43.0, 2.1, 45.1, 65.6, 8.5, 9.3, 59.7, 20.5, 1.7, 12.9,\n",
    "             75.6, 37.9, 34.4, 38.9, 9.0, 8.7, 44.3, 11.9, 20.6, 37.0, 48.7, 14.2, 37.7,\n",
    "             9.5, 5.7, 50.5, 24.3, 45.2, 34.6, 30.7, 49.3, 25.6, 7.4, 5.4, 84.8, 21.6, 19.4,\n",
    "             57.6, 6.4, 18.4, 47.4, 17.0, 12.8, 13.1, 41.8, 20.3, 35.2, 23.7, 17.6, 8.3,\n",
    "             27.4, 29.7, 71.8, 30.0, 19.6, 26.6, 18.2, 3.7, 23.4, 5.8, 6.0, 31.6, 3.6, 6.0,\n",
    "             13.8, 8.1, 6.4, 66.2, 8.7]\n",
    "\n",
    "ventas = [22.1, 10.4, 9.3, 18.5, 12.9, 7.2, 11.8, 13.2, 4.8, 10.6, 8.6, 17.4, 9.2, 9.7,\n",
    "          19.0, 22.4, 12.5, 24.4, 11.3, 14.6, 18.0, 12.5, 5.6, 15.5, 9.7, 12.0, 15.0, 15.9,\n",
    "          18.9, 10.5, 21.4, 11.9, 9.6, 17.4, 9.5, 12.8, 25.4, 14.7, 10.1, 21.5, 16.6, 17.1,\n",
    "          20.7, 12.9, 8.5, 14.9, 10.6, 23.2, 14.8, 9.7, 11.4, 10.7, 22.6, 21.2, 20.2, 23.7,\n",
    "          5.5, 13.2, 23.8, 18.4, 8.1, 24.2, 15.7, 14.0, 18.0, 9.3, 9.5, 13.4, 18.9, 22.3,\n",
    "          18.3, 12.4, 8.8, 11.0, 17.0, 8.7, 6.9, 14.2, 5.3, 11.0, 11.8, 12.3, 11.3, 13.6,\n",
    "          21.7, 15.2, 12.0, 16.0, 12.9, 16.7, 11.2, 7.3, 19.4, 22.2, 11.5, 16.9, 11.7, 15.5,\n",
    "          25.4, 17.2, 11.7, 23.8, 14.8, 14.7, 20.7, 19.2, 7.2, 8.7, 5.3, 19.8, 13.4, 21.8,\n",
    "          14.1, 15.9, 14.6, 12.6, 12.2, 9.4, 15.9, 6.6, 15.5, 7.0, 11.6, 15.2, 19.7, 10.6,\n",
    "          6.6, 8.8, 24.7, 9.7, 1.6, 12.7, 5.7, 19.6, 10.8, 11.6, 9.5, 20.8, 9.6, 20.7, 10.9,\n",
    "          19.2, 20.1, 10.4, 11.4, 10.3, 13.2, 25.4, 10.9, 10.1, 16.1, 11.6, 16.6, 19.0, 15.6,\n",
    "          3.2, 15.3, 10.1, 7.3, 12.9, 14.4, 13.3, 14.9, 18.0, 11.9, 11.9, 8.0, 12.2, 17.1,\n",
    "          15.0, 8.4, 14.5, 7.6, 11.7, 11.5, 27.0, 20.2, 11.7, 11.8, 12.6, 10.5, 12.2, 8.7,\n",
    "          26.2, 17.6, 22.6, 10.3, 17.3, 15.9, 6.7, 10.8, 9.9, 5.9, 19.6, 17.3, 7.6, 9.7, 12.8,\n",
    "          25.5, 13.4]\n",
    "\n",
    "datos = pd.DataFrame({'tv': tv, 'radio': radio, 'periodico':periodico, 'ventas': ventas})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a264bda",
   "metadata": {},
   "source": [
    "# Relación entre variables\n",
    "\n",
    "\n",
    "El primer paso a la hora de establecer un modelo lineal múltiple es estudiar la relación que existe entre variables. Esta información es crítica a la hora de identificar cuáles pueden ser los mejores predictores para el modelo, y para detectar colinealidad entre predictores. A modo complementario, es recomendable representar la distribución de cada variable mediante histogramas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f5fc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlación entre columnas numéricas\n",
    "# ==============================================================================\n",
    "\n",
    "def tidy_corr_matrix(corr_mat):\n",
    "    '''\n",
    "    Función para convertir una matriz de correlación de pandas en formato tidy\n",
    "    '''\n",
    "    corr_mat = corr_mat.stack().reset_index()\n",
    "    corr_mat.columns = ['variable_1','variable_2','r']\n",
    "    corr_mat = corr_mat.loc[corr_mat['variable_1'] != corr_mat['variable_2'], :]\n",
    "    corr_mat['abs_r'] = np.abs(corr_mat['r'])\n",
    "    corr_mat = corr_mat.sort_values('abs_r', ascending=False)\n",
    "    \n",
    "    return(corr_mat)\n",
    "\n",
    "\n",
    "\n",
    "corr_matrix = datos.select_dtypes(include=['float64', 'int']).corr(method='pearson')\n",
    "tidy_corr_matrix(corr_matrix).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef81b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap matriz de correlaciones\n",
    "# ==============================================================================\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(6, 6))\n",
    "\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    annot     = True,\n",
    "    cbar      = False,\n",
    "    annot_kws = {\"size\": 19},\n",
    "    vmin      = -1,\n",
    "    vmax      = 1,\n",
    "    center    = 0,\n",
    "    cmap      = sns.diverging_palette(20, 220, n=200),\n",
    "    square    = True,\n",
    "    ax        = ax\n",
    ")\n",
    "\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation = 45,\n",
    "    horizontalalignment = 'right',\n",
    ")\n",
    "\n",
    "ax.tick_params(labelsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30a1af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de distribución para cada variable numérica\n",
    "# ==============================================================================\n",
    "# Ajustar número de subplots en función del número de columnas\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(9, 5))\n",
    "axes = axes.flat\n",
    "columnas_numeric = datos.select_dtypes(include=['float64', 'int']).columns\n",
    "\n",
    "for i, colum in enumerate(columnas_numeric):\n",
    "    sns.histplot(\n",
    "        data    = datos,\n",
    "        x       = colum,\n",
    "        stat    = \"count\",\n",
    "        kde     = True,\n",
    "        color   = (list(plt.rcParams['axes.prop_cycle'])*2)[i][\"color\"],\n",
    "        line_kws= {'linewidth': 2},\n",
    "        alpha   = 0.3,\n",
    "        ax      = axes[i]\n",
    "    )\n",
    "    axes[i].set_title(colum, fontsize = 10, fontweight = \"bold\")\n",
    "    axes[i].tick_params(labelsize = 8)\n",
    "    axes[i].set_xlabel(\"\")\n",
    "\n",
    "\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(top = 0.9)\n",
    "fig.suptitle('Distribución variables numéricas', fontsize = 10, fontweight = \"bold\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ac4bb4",
   "metadata": {},
   "source": [
    "# Ajuste del modelo\n",
    "\n",
    "\n",
    "Se ajusta un modelo lineal múltiple con el objetivo de predecir las ventas en función de la inversión en los tres canales de publicidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8bd7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# División de los datos en train y test\n",
    "# ==============================================================================\n",
    "X = datos[['tv', 'radio', 'periodico']]\n",
    "y = datos['ventas']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                        X,\n",
    "                                        y.values.reshape(-1,1),\n",
    "                                        train_size   = 0.8,\n",
    "                                        random_state = 1234,\n",
    "                                        shuffle      = True\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeb084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación del modelo utilizando el modo fórmula (similar a R)\n",
    "# ==============================================================================\n",
    "# datos_train = pd.DataFrame(\n",
    "#                     np.hstack((X_train, y_train)),\n",
    "#                     columns=['tv', 'radio', 'periodico', 'ventas']\n",
    "#               )\n",
    "# modelo = smf.ols(formula = 'ventas ~ tv + radio + periodico', data = datos_train)\n",
    "# modelo = modelo.fit()\n",
    "# print(modelo.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a23708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación del modelo utilizando matrices como en scikitlearn\n",
    "# ==============================================================================\n",
    "# A la matriz de predictores se le tiene que añadir una columna de 1s para el intercept del modelo\n",
    "X_train = sm.add_constant(X_train, prepend=True)\n",
    "\n",
    "modelo = sm.OLS(endog=y_train, exog=X_train,)\n",
    "\n",
    "modelo = modelo.fit()\n",
    "\n",
    "print(modelo.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7621f5",
   "metadata": {},
   "source": [
    "El modelo con todas las variables introducidas como predictores tiene un  𝑅2  alto (0.894), es capaz de explicar el 89.4% de la variabilidad observada en las ventas. El p-value del modelo es significativo (1.01e-75) por lo que se puede aceptar que el modelo es mejor que lo esperado es por azar, al menos uno de los coeficientes parciales de regresión es distinto de 0.\n",
    "\n",
    "Acorde al p-value obtenido para el coeficiente parcial de regresión de `periodico` (0.723), esta variable no contribuye de forma significativa al modelo. Se entrena de nuevo el modelo, pero esta vez excluyendo el predictor periodico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1591aa23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad25b912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación del modelo utilizando matrices\n",
    "# ==============================================================================\n",
    "# Se elimina la columna periodico del conjunto de train y test\n",
    "X_train = X_train.drop(columns = 'periodico')\n",
    "X_test  = X_test.drop(columns = 'periodico')\n",
    "\n",
    "# A la matriz de predictores se le tiene que añadir una columna de 1s para el\n",
    "# intercept del modelo\n",
    "X_train = sm.add_constant(X_train, prepend=True)\n",
    "\n",
    "modelo  = sm.OLS(endog=y_train, exog=X_train,)\n",
    "\n",
    "modelo  = modelo.fit()\n",
    "\n",
    "print(modelo.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2db0301",
   "metadata": {},
   "source": [
    "# Intervalos de confianza de los coeficientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21a066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intervalos de confianza para los coeficientes del modelo\n",
    "# ==============================================================================\n",
    "intervalos_ci = modelo.conf_int(alpha=0.05)\n",
    "intervalos_ci.columns = ['2.5%', '97.5%']\n",
    "intervalos_ci"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afbd25c",
   "metadata": {},
   "source": [
    "# Diagnostico de los residuos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d9bb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnóstico errores (residuos) de las predicciones de entrenamiento\n",
    "# ==============================================================================\n",
    "y_train = y_train.flatten()\n",
    "prediccion_train = modelo.predict(exog = X_train)\n",
    "residuos_train   = prediccion_train - y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0e6f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráficos\n",
    "# ==============================================================================\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(9, 8))\n",
    "\n",
    "axes[0, 0].scatter(y_train, prediccion_train, edgecolors=(0, 0, 0), alpha = 0.4)\n",
    "axes[0, 0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()],\n",
    "                'k--', color = 'black', lw=2)\n",
    "axes[0, 0].set_title('Valor predicho vs valor real', fontsize = 10, fontweight = \"bold\")\n",
    "axes[0, 0].set_xlabel('Real')\n",
    "axes[0, 0].set_ylabel('Predicción')\n",
    "axes[0, 0].tick_params(labelsize = 7)\n",
    "\n",
    "axes[0, 1].scatter(list(range(len(y_train))), residuos_train,\n",
    "                   edgecolors=(0, 0, 0), alpha = 0.4)\n",
    "axes[0, 1].axhline(y = 0, linestyle = '--', color = 'black', lw=2)\n",
    "axes[0, 1].set_title('Residuos del modelo', fontsize = 10, fontweight = \"bold\")\n",
    "axes[0, 1].set_xlabel('id')\n",
    "axes[0, 1].set_ylabel('Residuo')\n",
    "axes[0, 1].tick_params(labelsize = 7)\n",
    "\n",
    "sns.histplot(\n",
    "    data    = residuos_train,\n",
    "    stat    = \"density\",\n",
    "    kde     = True,\n",
    "    line_kws= {'linewidth': 1},\n",
    "    color   = \"firebrick\",\n",
    "    alpha   = 0.3,\n",
    "    ax      = axes[1, 0]\n",
    ")\n",
    "\n",
    "axes[1, 0].set_title('Distribución residuos del modelo', fontsize = 10,\n",
    "                     fontweight = \"bold\")\n",
    "axes[1, 0].set_xlabel(\"Residuo\")\n",
    "axes[1, 0].tick_params(labelsize = 7)\n",
    "\n",
    "\n",
    "sm.qqplot(\n",
    "    residuos_train,\n",
    "    fit   = True,\n",
    "    line  = 'q',\n",
    "    ax    = axes[1, 1], \n",
    "    color = 'firebrick',\n",
    "    alpha = 0.4,\n",
    "    lw    = 2\n",
    ")\n",
    "axes[1, 1].set_title('Q-Q residuos del modelo', fontsize = 10, fontweight = \"bold\")\n",
    "axes[1, 1].tick_params(labelsize = 7)\n",
    "\n",
    "axes[2, 0].scatter(prediccion_train, residuos_train,\n",
    "                   edgecolors=(0, 0, 0), alpha = 0.4)\n",
    "axes[2, 0].axhline(y = 0, linestyle = '--', color = 'black', lw=2)\n",
    "axes[2, 0].set_title('Residuos del modelo vs predicción', fontsize = 10, fontweight = \"bold\")\n",
    "axes[2, 0].set_xlabel('Predicción')\n",
    "axes[2, 0].set_ylabel('Residuo')\n",
    "axes[2, 0].tick_params(labelsize = 7)\n",
    "\n",
    "# Se eliminan los axes vacíos\n",
    "fig.delaxes(axes[2,1])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "fig.suptitle('Diagnóstico residuos', fontsize = 12, fontweight = \"bold\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4dad76",
   "metadata": {},
   "source": [
    "Los residuos no parecen distribuirse de forma aleatoria en torno a cero, sin mantener aproximadamente la misma variabilidad a lo largo del eje X. Este patrón apunta a una falta de homocedasticidad y de distribución normal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c26099",
   "metadata": {},
   "source": [
    "# Test de normalidad\n",
    "\n",
    "\n",
    "Se comprueba si los residuos siguen una distribución normal empleando dos test estadísticos: Shapiro-Wilk test y D'Agostino's K-squared test. Este último es el que incluye el summary de statsmodels bajo el nombre de Omnibus.\n",
    "\n",
    "En ambos test, **la hipótesis nula considera que los datos siguen una distribución normal**, por lo tanto, si el p-value no es inferior al nivel de referencia alpha seleccionado, no hay evidencias para descartar que los datos se distribuyen de forma normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f546a4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalidad de los residuos Shapiro-Wilk test\n",
    "# ==============================================================================\n",
    "shapiro_test = stats.shapiro(residuos_train)\n",
    "shapiro_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ad7124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalidad de los residuos D'Agostino's K-squared test\n",
    "# ==============================================================================\n",
    "k2, p_value = stats.normaltest(residuos_train)\n",
    "print(f\"Estadítico= {k2}, p-value = {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a2e0ff",
   "metadata": {},
   "source": [
    "Ambos test muestran claras evidencias para rechazar la hipótesis de que los datos se distribuyen de forma normal (p-value << 0.01)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec62ebc4",
   "metadata": {},
   "source": [
    "# Predicciones\n",
    "\n",
    "\n",
    "Una vez entrenado el modelo, se pueden obtener predicciones para nuevos datos. Los modelos de statsmodels permiten calcular los intervalos de confianza asociados a cada predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60df97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones con intervalo de confianza \n",
    "# ==============================================================================\n",
    "predicciones = modelo.get_prediction(exog = X_train).summary_frame(alpha=0.05)\n",
    "predicciones.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a210024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error de test del modelo \n",
    "# ==============================================================================\n",
    "X_test = sm.add_constant(X_test, prepend=True)\n",
    "predicciones = modelo.predict(exog = X_test)\n",
    "rmse = mean_squared_error(\n",
    "        y_true  = y_test,\n",
    "        y_pred  = predicciones,\n",
    "        squared = False\n",
    "       )\n",
    "print(\"\")\n",
    "print(f\"El error (rmse) de test es: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417cfb2b",
   "metadata": {},
   "source": [
    "# Interpretación\n",
    "El modelo de regresión lineal múltiple:\n",
    "\n",
    "- $ventas = 2.9004 + 0.0456tv + 0.1904radio$\n",
    " \n",
    "es capaz de explicar el 89.4% de la varianza observada en las ventas (R-squared: 0.894, Adj. R-squared: 0.892). El test  𝐹  es significativo (p-value: 3.69e-77). Por lo que hay evidencias claras de que el modelo es capaz de explicar la varianza en las ventas mejor de lo esperado por azar. Los test estadísticos para cada variable confirman que tv y radio están relacionadas con la cantidad de ventas y contribuyen al modelo.\n",
    "\n",
    "No se satisfacen las condiciones de normalidad, por lo que los intervalos de confianza estimados para los coeficientes y las predicciones no son fiables.\n",
    "\n",
    "El error (rmse) de test es de 1.696. Las predicciones del modelo final se alejan en promedio 1.696 unidades del valor real.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b93ef5",
   "metadata": {},
   "source": [
    "# Interacción entre predictores\n",
    "\n",
    "\n",
    "El modelo lineal a partir del cual se han obtenido las conclusiones asume que el efecto sobre las ventas debido a un incremento en el presupuesto de uno de los medios de comunicación es independiente del presupuesto gastado en los otros. Por ejemplo, el modelo lineal considera que el efecto promedio sobre las ventas debido a aumentar en una unidad el presupuesto de anuncios en TV es siempre de 0.0456, independientemente de la cantidad invertida en anuncios por radio. Sin embargo, esto no tiene por qué ser necesariamente así, puede existir interacción entre los predictores de forma que, el efecto de cada uno de ellos sobre la variable respuesta, depende en cierta medida del valor que tome el otro predictor.\n",
    "\n",
    "Tal y como se ha definido previamente, un modelo lineal con dos predictores sigue la ecuación:\n",
    "\n",
    "$y=\\beta_{0}+\\beta_{1}x_{1}+\\beta_{2}x_{2}+\\epsilon$\n",
    " \n",
    "Acorde a esta definición, el incremento de una unidad en el predictor  𝑥1  produce un incremento promedio de la variable y de  𝛽1. Modificaciones en el predictor  𝑥2  no alteran este hecho, y lo mismo ocurre con  𝑥2  respecto a  𝑥1. Para que el modelo pueda contemplar la interacción entre ambos, se introduce un tercer predictor, llamado interaction term, que se construye con el producto de los predictores  𝑥1  y  𝑥2 .\n",
    "\n",
    "$y=\\beta_{0}+\\beta_{1}x_{1}+\\beta_{2}x_{2}+\\beta_{3}x_{1}x_{2} + e$\n",
    " \n",
    "La reorganización de los términos resulta en:\n",
    "\n",
    "$y=\\beta_{0}+(\\beta_{1} + \\beta_{3}x_2)x_{1}+\\beta_{2}x_{2}+ e$\n",
    " \n",
    "El efecto de  𝑥1  sobre  𝑦  ya no es constante, sino que depende del valor que tome  𝑥2 .\n",
    "\n",
    "En los modelos de regresión lineal múltiple que incorporan interacciones entre predictores hay que tener en cuenta el hierarchical principle, según el cual, si se incorpora al modelo una interacción entre predictores, se deben incluir siempre los predictores individuales que participan en la interacción, independientemente de que su p-value sea significativo o no.\n",
    "\n",
    "En stastmodels se puede introducir interacción entre predictores de dos formas:\n",
    "\n",
    "- Indicandolo en la fórmula con el término `*`: $ventas \\sim tv * radio$\n",
    "\n",
    "- Añadiendo una nueva columna con la multiplicación de los predictores cuya interacción se quiere incluir en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3659d98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# División de los datos en train y test\n",
    "# ==============================================================================\n",
    "X = datos[['tv', 'radio']]\n",
    "y = datos['ventas']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                        X,\n",
    "                                        y.values.reshape(-1,1),\n",
    "                                        train_size   = 0.8,\n",
    "                                        random_state = 1234,\n",
    "                                        shuffle      = True\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eef657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación del modelo con interacciones utilizando el modo fórmula (similar a R)\n",
    "# ==============================================================================\n",
    "# datos_train = pd.DataFrame(\n",
    "#                     np.hstack((X_train, y_train)),\n",
    "#                     columns=['tv', 'radio', 'ventas']\n",
    "#               )\n",
    "# modelo_interacion = smf.ols(formula = 'ventas ~ tv*radio', data = datos_train)\n",
    "# modelo_interacion = modelo_interacion.fit()\n",
    "# print(modelo_interacion.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68061550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación del modelo con interacciones utilizando matrices\n",
    "# ==============================================================================\n",
    "# Se añade una nueva columna con la interacción\n",
    "X_train['tv_radio'] = X_train['tv'] * X_train['radio']\n",
    "X_test['tv_radio']  = X_test['tv']  * X_test['radio']\n",
    "\n",
    "# A la matriz de predictores se le tiene que añadir una columna de 1s\n",
    "# para el intercept del modelo\n",
    "X_train = sm.add_constant(X_train, prepend=True)\n",
    "\n",
    "modelo_interacion  = sm.OLS(endog=y_train, exog=X_train,)\n",
    "modelo_interacion  = modelo_interacion.fit()\n",
    "print(modelo_interacion.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314f5770",
   "metadata": {},
   "source": [
    "Los resultados muestran una evidencia clara de que la interacción tv radio es significativa (p-value* muy próximo a 0).\n",
    "\n",
    "El modelo que incorpora la interacción tiene un Adjusted R-squared de 0.967, un valor superior al 0.892 del modelo que solo contemplaba el efecto de los predictores por separado. Ahora bien, ¿Es suficiente esta diferencia para afirmar que el modelo con interacción es superior? Una forma de responder a esta pregunta es recurriendo al F-test (ANOVA)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832227b8",
   "metadata": {},
   "source": [
    "# Logaritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7937340c",
   "metadata": {},
   "source": [
    "<img src=\"./img/loga.png\" width=\"600\">\n",
    "<img src=\"./img/forma_func.png\" width=\"600\">\n",
    "<img src=\"./img/forma_func2.png\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ded29e",
   "metadata": {},
   "source": [
    "# Comparación de modelos mediante test F-test (ANOVA)\n",
    "\n",
    "\n",
    "Supóngase un modelo  𝑀  y otro modelo  𝑚 , de menor tamaño, formado por un subconjunto de los predictores contenidos en  𝑀 . Si la diferencia en el ajuste es muy pequeña, acorde al principio de parsimonia, el modelo  𝑚  es más adecuado. Es posible contrastar si la diferencia en ajuste es significativa mediante la comparación de los residuos. En concreto el estadístico empleado es:\n",
    "\n",
    "- $\\frac{RSS_m - RSS_M}{RSS_M}$\n",
    " \n",
    "Para evitar que el tamaño del modelo influya en el contraste, se divide la suma de residuos cuadrados RSS de cada modelo entre sus grados de libertad. El estadístico resultante sigue una distribución  𝐹 .\n",
    "\n",
    "- $\\frac{(RSS_m - RSS_M)/(df_m - df_M)}{RSS_M/(df_M)} \\sim F_{df_m-df_M, \\ df_M}$\n",
    " \n",
    "donde  𝑑𝑓  son los grados de libertad del modelo, que equivalen al número de observaciones menos el número de predictores.\n",
    "\n",
    "En los apartados anteriores, se entrenó un modelo que incluía interacciones y otro que no. Se procede a realizar un test de hipótesis que evalúe la hipótesis nula de que ambos modelos se ajustan a los datos igual de bien. Es decir, que permita determinar si un modelo es mejor que el otro prediciendo la variable respuesta. Esto puede hacerse con la función anova_lm() de statsmodels.stats.anova."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccb3320",
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_lm(modelo, modelo_interacion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a01aba",
   "metadata": {},
   "source": [
    "El test ANOVA encuentra evidencias claras (p-value prácticamente de cero) de que el modelo que incluye la interacción entre predictores es capaz de modelar mejor la variable respuesta.\n",
    "\n",
    "Esta forma de comparar modelos está muy arraigada en la comunidad estadística. En la comunidad de machine learning es mucho más común comparar modelos con técnicas de validación como la `validación cruzada` o `cross-validation`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0747146e8c25edbf23b06660f56c13d904416c90b78e9de58be7b82a82661032"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
