{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación del Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import opendatasets as od\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifierCV\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "#from sklearn.metrics import accuracy_scor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7f8e96a9cfedcda9da89eeaf848f74555a156869"
   },
   "source": [
    "### Descarga de Datasets desde Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \".\\titanic\" (use force=True to force download)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'username': 'dgrone', 'key': '8e16739c70ce24ea1e6d9a45b61e9796'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "od.download(\"https://www.kaggle.com/c/titanic/data\")\n",
    "{\"username\":\"dgrone\",\"key\":\"8e16739c70ce24ea1e6d9a45b61e9796\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_folder = \"c:/Users/pablo/OneDrive/Documentos/GitHub/MDS-Notebooks/03-MLA/titanic/train.csv\"\n",
    "train_folder = \"titanic/train.csv\"\n",
    "train_df = pd.read_csv(train_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_folder = \"c:/Users/pablo/OneDrive/Documentos/GitHub/MDS-Notebooks/03-MLA/titanic/test.csv\"\n",
    "test_folder = \"titanic/test.csv\"\n",
    "test_df = pd.read_csv(test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This variable contains whether the passenger survived or not\n",
    "y = train_data['Survived'].values\n",
    "\n",
    "# The features to train on\n",
    "features = ['Pclass', 'Sex', 'Age']\n",
    "# Taking only the features we need\n",
    "df_X = train_data[features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[0;32m     14\u001b[0m mmsc \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[1;32m---> 15\u001b[0m df_X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m mmsc\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mdf_X\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAge\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m(\u001b[38;5;28mlen\u001b[39m(df_X), \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Splitting the dataset into training and testing\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5569\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5570\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5571\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5572\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5573\u001b[0m ):\n\u001b[0;32m   5574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "# To encode the feature Sex \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_sex = LabelEncoder()\n",
    "df_X['Sex'] = le_sex.fit_transform(df_X['Sex'])\n",
    "# male = 1, female = 0\n",
    "\n",
    "\n",
    "\n",
    "# Replacing nan with the mean of age\n",
    "age_mean =df_X['Age'].mean()\n",
    "df_X['Age'] = df_X['Age'].fillna(age_mean)\n",
    "# To normalize Age and convert them to a value between 0 & 1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mmsc = MinMaxScaler()\n",
    "df_X['Age'] = mmsc.fit_transform(df_X['Age'].reshape(len(df_X), 1))\n",
    "\n",
    "# Splitting the dataset into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X.values, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step2 - Building the model\n",
    "\n",
    "# Importing the required modules\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Initializing the model\n",
    "model = Sequential()\n",
    "\n",
    "# Adding the input layer and first hidden layer\n",
    "model.add(Dense(input_dim=5, units=32, activation='relu'))\n",
    "model.add(Dropout(rate=0.3)) # Try reducing the dropout rate\n",
    "\n",
    "# Adding the second hidden layer\n",
    "model.add(Dense(units=16, activation='relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train, batch_size=10, epochs=500)\n",
    "# Try reducing the batch size and changing the number of epochs\n",
    "\n",
    "\n",
    "# Step3 - Making predictions \n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "predictions[predictions >= 0.6] = 1 # survived\n",
    "predictions[predictions < 0.6] = 0 # did not survive\n",
    "\n",
    "correct_count=0\n",
    "for i in range(len(X_test)):\n",
    "    if predictions[i] == y_test[i]:\n",
    "        correct_count+=1\n",
    "\n",
    "accuracy = correct_count / len(X_test)\n",
    "print(\"Actual Accuracy = \", accuracy)\n",
    "\n",
    "jack = [1, mmsc.transform(20), 0, 0, 1]\n",
    "jack_survived = model.predict(np.array(jack).reshape(1, 5))\n",
    "print(\"Chances of Jack surviving = \", jack_survived[0][0]*100)\n",
    "\n",
    "rose = [0, mmsc.transform(17), 1, 0, 0]\n",
    "rose_survived = model.predict(np.array(rose).reshape(1, 5))\n",
    "print(\"Chances of Rose surviving = \", rose_survived[0][0]*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
