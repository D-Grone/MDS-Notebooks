{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a281973",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Redes Neuronales\n",
    "### v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b429ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import sklearn.neural_network\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras import models, layers, optimizers, regularizers\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# En keras los regularizadores estan en regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0458ad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wines = load_wine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aeec16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# para poner nombres\n",
    "features = wines.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67378f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Separacion tradicional\n",
    "X_train, X_test, y_train, y_test = train_test_split(wines.data,\n",
    "                                                    wines.target,test_size=0.3,random_state=123)\n",
    "\n",
    "## Estandarizado, no normalizado!\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(wines.data)\n",
    "\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e9a168b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Hemos visto hasta ahora los perceptrones multicapa. MLPClassifier es eso.\n",
    "\n",
    "#\n",
    "# activation{‘identity’, ‘logistic’, ‘tanh’, ‘relu’}, default=’relu’\n",
    "# solver{‘lbfgs’, ‘sgd’, ‘adam’}, default=’adam’\n",
    "# alpha asociado a regularizacion l2, basado en la fuerza de la regularizacion\n",
    "# learning_rate opera solo si solver es 'sgd'\n",
    "clf = sklearn.neural_network.MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), \n",
    "                                           random_state=1,\n",
    "                                           verbose=True)\n",
    "\n",
    "#clf2 = sklearn.neural_network.MLPClassifier(activation = 'identity',\n",
    "#                                            solver='sgd', \n",
    "#                                            alpha=1e-5,\n",
    "#                    hidden_layer_sizes=(5, 2), learning_rate = 'adaptative',\n",
    "#                                            random_state=1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "sklearn.neural_network.MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,\n",
    "              solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb56f505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf2.fit(X_train, y_train)\n",
    "# Por que pasa esto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db7513b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted   0   1   2  All\n",
       "real                      \n",
       "0          14   0   0   14\n",
       "1           0  18   0   18\n",
       "2           0   1  21   22\n",
       "All        14  19  21   54"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = pd.DataFrame({'predicted': clf.predict(X_test),\n",
    "             'real': y_test})\n",
    "\n",
    "pd.crosstab(index=df['real'], columns=df['predicted'], margins=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12b45db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "hidden_units = 10     # how many neurons in the hidden layer\n",
    "activation = 'relu'   # activation function for hidden layer\n",
    "l2 = 0.01             # regularization - how much we penalize large parameter values\n",
    "                     \n",
    "learning_rate = 0.01  # how big our steps are in gradient descent\n",
    "epochs = 7            # how many epochs to train for\n",
    "batch_size = 16       # how many samples to use for each gradient descent update\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f25f1168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 1s 3ms/step - loss: 12.0705 - accuracy: 0.3710\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 6.0215 - accuracy: 0.4516\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: -1.6092 - accuracy: 0.6210\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: -2.8045 - accuracy: 0.6532\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: -2.9137 - accuracy: 0.7581\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: -2.9654 - accuracy: 0.7500\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: -2.9842 - accuracy: 0.7500\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: -2.9998 - accuracy: 0.7581\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: -3.0140 - accuracy: 0.7661\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: -3.0300 - accuracy: 0.7742\n",
      "4/4 [==============================] - 0s 3ms/step - loss: -3.0381 - accuracy: 0.7742\n",
      "2/2 [==============================] - 0s 0s/step - loss: -6.1523 - accuracy: 0.5741\n",
      "Training accuracy: 0.774193525314331\n",
      "Testing accuracy: 0.5740740895271301\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# create a seModeloquential model\n",
    "## Viene de KERAS!\n",
    "model = models.Sequential()\n",
    "\n",
    "# Primera capa oculta de 20 nodos\n",
    "model.add(layers.Dense(input_dim=len(features),\n",
    "                       units=hidden_units, \n",
    "                       activation=activation))\n",
    "\n",
    "# Primera capa oculta de 20 nodos\n",
    "model.add(layers.Dense(input_dim=hidden_units,\n",
    "                       units=hidden_units, \n",
    "                       activation=activation))\n",
    "\n",
    "# final de la red, outputs\n",
    "model.add(layers.Dense(input_dim=hidden_units,\n",
    "                       units=1,\n",
    "                       activation='relu'))\n",
    "\n",
    "# define our loss function and optimizer\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              # Adam is a kind of gradient descent\n",
    "              optimizer=optimizers.Adam(learning_rate=learning_rate),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train the parameters\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=batch_size)\n",
    "\n",
    "# evaluate accuracy\n",
    "train_acc = model.evaluate(X_train, y_train, batch_size=32)[1]\n",
    "test_acc = model.evaluate(X_test, y_test, batch_size=32)[1]\n",
    "print('Training accuracy: %s' % train_acc)\n",
    "print('Testing accuracy: %s' % test_acc)\n",
    "\n",
    "losses = history.history['loss']\n",
    "plt.plot(range(len(losses)), losses, 'r')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95a1161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create a seModeloquential model\n",
    "## Viene de KERAS!\n",
    "model = models.Sequential()\n",
    "\n",
    "# Primera capa oculta de 20 nodos\n",
    "model.add(layers.Dense(input_dim=len(features),\n",
    "                       units=hidden_units, \n",
    "                       activation=activation,\n",
    "          kernel_regularizer = regularizers.l1(1e-6)))\n",
    "\n",
    "# segunda capa oculta de 20 nodos\n",
    "model.add(layers.Dense(input_dim=hidden_units,\n",
    "                       units=hidden_units, \n",
    "                       activation=activation))\n",
    "\n",
    "# final de la red, outputs\n",
    "model.add(layers.Dense(input_dim=hidden_units,\n",
    "                       units=1,\n",
    "                       activation='relu'))\n",
    "\n",
    "# define our loss function and optimizer\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(learning_rate=learning_rate),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccf49f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: -1.0445 - accuracy: 0.6694\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: -2.9950 - accuracy: 0.7500\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: -3.0447 - accuracy: 0.7742\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: -3.0639 - accuracy: 0.7823\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: -3.0707 - accuracy: 0.7823\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: -3.0720 - accuracy: 0.7823\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: -3.0730 - accuracy: 0.7823\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: -3.0730 - accuracy: 0.7823\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: -3.0730 - accuracy: 0.7823\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: -3.0730 - accuracy: 0.7823\n"
     ]
    }
   ],
   "source": [
    "# train the parameters\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d01e37c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: -3.0730 - accuracy: 0.7823\n",
      "2/2 [==============================] - 0s 8ms/step - loss: -5.9025 - accuracy: 0.5741\n",
      "Training accuracy: 0.7822580933570862\n",
      "Testing accuracy: 0.5740740895271301\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# evaluate accuracy\n",
    "train_acc = model.evaluate(X_train, y_train, batch_size=32)[1]\n",
    "test_acc = model.evaluate(X_test, y_test, batch_size=32)[1]\n",
    "print('Training accuracy: %s' % train_acc)\n",
    "print('Testing accuracy: %s' % test_acc)\n",
    "\n",
    "losses = history.history['loss']\n",
    "plt.plot(range(len(losses)), losses, 'r')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a6c861",
   "metadata": {},
   "source": [
    "## Entonces, mejora en algo? pues mejoro un poco la prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed446604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "california = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c5912e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['MedInc',\n",
       "  'HouseAge',\n",
       "  'AveRooms',\n",
       "  'AveBedrms',\n",
       "  'Population',\n",
       "  'AveOccup',\n",
       "  'Latitude',\n",
       "  'Longitude'],\n",
       " array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]),\n",
       " (20640, 8))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "california.feature_names,california.target, california.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b39f29c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Estandarizado, no normalizado!\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(california.data)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(california.data,california.target,test_size=0.3,random_state=123)\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbde9cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.26166861\n",
      "Iteration 2, loss = 0.77521332\n",
      "Iteration 3, loss = 0.64884565\n",
      "Iteration 4, loss = 0.57095882\n",
      "Iteration 5, loss = 0.49548317\n",
      "Iteration 6, loss = 0.42373763\n",
      "Iteration 7, loss = 0.36834685\n",
      "Iteration 8, loss = 0.33423110\n",
      "Iteration 9, loss = 0.31611752\n",
      "Iteration 10, loss = 0.30530432\n",
      "Iteration 11, loss = 0.29850573\n",
      "Iteration 12, loss = 0.29358309\n",
      "Iteration 13, loss = 0.28958253\n",
      "Iteration 14, loss = 0.28622715\n",
      "Iteration 15, loss = 0.28330139\n",
      "Iteration 16, loss = 0.28065061\n",
      "Iteration 17, loss = 0.27822887\n",
      "Iteration 18, loss = 0.27601061\n",
      "Iteration 19, loss = 0.27404174\n",
      "Iteration 20, loss = 0.27217558\n",
      "Iteration 21, loss = 0.27033030\n",
      "Iteration 22, loss = 0.26860774\n",
      "Iteration 23, loss = 0.26693238\n",
      "Iteration 24, loss = 0.26531444\n",
      "Iteration 25, loss = 0.26393603\n",
      "Iteration 26, loss = 0.26250998\n",
      "Iteration 27, loss = 0.26121148\n",
      "Iteration 28, loss = 0.25997376\n",
      "Iteration 29, loss = 0.25884843\n",
      "Iteration 30, loss = 0.25787454\n",
      "Iteration 31, loss = 0.25703915\n",
      "Iteration 32, loss = 0.25604816\n",
      "Iteration 33, loss = 0.25518615\n",
      "Iteration 34, loss = 0.25444206\n",
      "Iteration 35, loss = 0.25364885\n",
      "Iteration 36, loss = 0.25300936\n",
      "Iteration 37, loss = 0.25193926\n",
      "Iteration 38, loss = 0.25108996\n",
      "Iteration 39, loss = 0.25030834\n",
      "Iteration 40, loss = 0.24960828\n",
      "Iteration 41, loss = 0.24875194\n",
      "Iteration 42, loss = 0.24800593\n",
      "Iteration 43, loss = 0.24730769\n",
      "Iteration 44, loss = 0.24666763\n",
      "Iteration 45, loss = 0.24593172\n",
      "Iteration 46, loss = 0.24527621\n",
      "Iteration 47, loss = 0.24459490\n",
      "Iteration 48, loss = 0.24391168\n",
      "Iteration 49, loss = 0.24328329\n",
      "Iteration 50, loss = 0.24274395\n",
      "Iteration 51, loss = 0.24213095\n",
      "Iteration 52, loss = 0.24159342\n",
      "Iteration 53, loss = 0.24109740\n",
      "Iteration 54, loss = 0.24056197\n",
      "Iteration 55, loss = 0.24000644\n",
      "Iteration 56, loss = 0.23947642\n",
      "Iteration 57, loss = 0.23907709\n",
      "Iteration 58, loss = 0.23858228\n",
      "Iteration 59, loss = 0.23820174\n",
      "Iteration 60, loss = 0.23755171\n",
      "Iteration 61, loss = 0.23719308\n",
      "Iteration 62, loss = 0.23673644\n",
      "Iteration 63, loss = 0.23641022\n",
      "Iteration 64, loss = 0.23594512\n",
      "Iteration 65, loss = 0.23549481\n",
      "Iteration 66, loss = 0.23515587\n",
      "Iteration 67, loss = 0.23469156\n",
      "Iteration 68, loss = 0.23440343\n",
      "Iteration 69, loss = 0.23398430\n",
      "Iteration 70, loss = 0.23360612\n",
      "Iteration 71, loss = 0.23319394\n",
      "Iteration 72, loss = 0.23295273\n",
      "Iteration 73, loss = 0.23260207\n",
      "Iteration 74, loss = 0.23220940\n",
      "Iteration 75, loss = 0.23179450\n",
      "Iteration 76, loss = 0.23150287\n",
      "Iteration 77, loss = 0.23115494\n",
      "Iteration 78, loss = 0.23075490\n",
      "Iteration 79, loss = 0.23039512\n",
      "Iteration 80, loss = 0.22999628\n",
      "Iteration 81, loss = 0.22969381\n",
      "Iteration 82, loss = 0.22931756\n",
      "Iteration 83, loss = 0.22903960\n",
      "Iteration 84, loss = 0.22868735\n",
      "Iteration 85, loss = 0.22837553\n",
      "Iteration 86, loss = 0.22802968\n",
      "Iteration 87, loss = 0.22769953\n",
      "Iteration 88, loss = 0.22740581\n",
      "Iteration 89, loss = 0.22707972\n",
      "Iteration 90, loss = 0.22678745\n",
      "Iteration 91, loss = 0.22645337\n",
      "Iteration 92, loss = 0.22618341\n",
      "Iteration 93, loss = 0.22584078\n",
      "Iteration 94, loss = 0.22559350\n",
      "Iteration 95, loss = 0.22523535\n",
      "Iteration 96, loss = 0.22498369\n",
      "Iteration 97, loss = 0.22465978\n",
      "Iteration 98, loss = 0.22440006\n",
      "Iteration 99, loss = 0.22412677\n",
      "Iteration 100, loss = 0.22379886\n",
      "Iteration 101, loss = 0.22353160\n",
      "Iteration 102, loss = 0.22322940\n",
      "Iteration 103, loss = 0.22300976\n",
      "Iteration 104, loss = 0.22266388\n",
      "Iteration 105, loss = 0.22249328\n",
      "Iteration 106, loss = 0.22223387\n",
      "Iteration 107, loss = 0.22180708\n",
      "Iteration 108, loss = 0.22165036\n",
      "Iteration 109, loss = 0.22128717\n",
      "Iteration 110, loss = 0.22103445\n",
      "Iteration 111, loss = 0.22079704\n",
      "Iteration 112, loss = 0.22049058\n",
      "Iteration 113, loss = 0.22023244\n",
      "Iteration 114, loss = 0.21994933\n",
      "Iteration 115, loss = 0.21969383\n",
      "Iteration 116, loss = 0.21933956\n",
      "Iteration 117, loss = 0.21905540\n",
      "Iteration 118, loss = 0.21871657\n",
      "Iteration 119, loss = 0.21843486\n",
      "Iteration 120, loss = 0.21822768\n",
      "Iteration 121, loss = 0.21799438\n",
      "Iteration 122, loss = 0.21773885\n",
      "Iteration 123, loss = 0.21748376\n",
      "Iteration 124, loss = 0.21720630\n",
      "Iteration 125, loss = 0.21691084\n",
      "Iteration 126, loss = 0.21669509\n",
      "Iteration 127, loss = 0.21636253\n",
      "Iteration 128, loss = 0.21608334\n",
      "Iteration 129, loss = 0.21583595\n",
      "Iteration 130, loss = 0.21558559\n",
      "Iteration 131, loss = 0.21532190\n",
      "Iteration 132, loss = 0.21510918\n",
      "Iteration 133, loss = 0.21481841\n",
      "Iteration 134, loss = 0.21451004\n",
      "Iteration 135, loss = 0.21423539\n",
      "Iteration 136, loss = 0.21404352\n",
      "Iteration 137, loss = 0.21375050\n",
      "Iteration 138, loss = 0.21367853\n",
      "Iteration 139, loss = 0.21335270\n",
      "Iteration 140, loss = 0.21306234\n",
      "Iteration 141, loss = 0.21284496\n",
      "Iteration 142, loss = 0.21270959\n",
      "Iteration 143, loss = 0.21234128\n",
      "Iteration 144, loss = 0.21219054\n",
      "Iteration 145, loss = 0.21206081\n",
      "Iteration 146, loss = 0.21172749\n",
      "Iteration 147, loss = 0.21142983\n",
      "Iteration 148, loss = 0.21132482\n",
      "Iteration 149, loss = 0.21101007\n",
      "Iteration 150, loss = 0.21085228\n",
      "Iteration 151, loss = 0.21054848\n",
      "Iteration 152, loss = 0.21037044\n",
      "Iteration 153, loss = 0.21018937\n",
      "Iteration 154, loss = 0.20992129\n",
      "Iteration 155, loss = 0.20969399\n",
      "Iteration 156, loss = 0.20950814\n",
      "Iteration 157, loss = 0.20936964\n",
      "Iteration 158, loss = 0.20913645\n",
      "Iteration 159, loss = 0.20893358\n",
      "Iteration 160, loss = 0.20852444\n",
      "Iteration 161, loss = 0.20835327\n",
      "Iteration 162, loss = 0.20820340\n",
      "Iteration 163, loss = 0.20793879\n",
      "Iteration 164, loss = 0.20779654\n",
      "Iteration 165, loss = 0.20761864\n",
      "Iteration 166, loss = 0.20749211\n",
      "Iteration 167, loss = 0.20736916\n",
      "Iteration 168, loss = 0.20711300\n",
      "Iteration 169, loss = 0.20703271\n",
      "Iteration 170, loss = 0.20682734\n",
      "Iteration 171, loss = 0.20675707\n",
      "Iteration 172, loss = 0.20648004\n",
      "Iteration 173, loss = 0.20633667\n",
      "Iteration 174, loss = 0.20640772\n",
      "Iteration 175, loss = 0.20603965\n",
      "Iteration 176, loss = 0.20596253\n",
      "Iteration 177, loss = 0.20600148\n",
      "Iteration 178, loss = 0.20573707\n",
      "Iteration 179, loss = 0.20563914\n",
      "Iteration 180, loss = 0.20551330\n",
      "Iteration 181, loss = 0.20527070\n",
      "Iteration 182, loss = 0.20538164\n",
      "Iteration 183, loss = 0.20504665\n",
      "Iteration 184, loss = 0.20513056\n",
      "Iteration 185, loss = 0.20487668\n",
      "Iteration 186, loss = 0.20473130\n",
      "Iteration 187, loss = 0.20460919\n",
      "Iteration 188, loss = 0.20470091\n",
      "Iteration 189, loss = 0.20444562\n",
      "Iteration 190, loss = 0.20440466\n",
      "Iteration 191, loss = 0.20432501\n",
      "Iteration 192, loss = 0.20414473\n",
      "Iteration 193, loss = 0.20403560\n",
      "Iteration 194, loss = 0.20397554\n",
      "Iteration 195, loss = 0.20400049\n",
      "Iteration 196, loss = 0.20387401\n",
      "Iteration 197, loss = 0.20366175\n",
      "Iteration 198, loss = 0.20368598\n",
      "Iteration 199, loss = 0.20367312\n",
      "Iteration 200, loss = 0.20346306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pablo\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,\n",
       "             solver='sgd', verbose=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpR = sklearn.neural_network.MLPRegressor(solver='sgd', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), \n",
    "                                           random_state=1,\n",
    "                                           verbose=True)\n",
    "mlpR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a0bdbd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>1.0067065336828516</th>\n",
       "      <th>1.0075261674184892</th>\n",
       "      <th>1.0088308245427258</th>\n",
       "      <th>1.0088450955681576</th>\n",
       "      <th>1.0097351029747441</th>\n",
       "      <th>1.0100842996797554</th>\n",
       "      <th>1.0102444642468156</th>\n",
       "      <th>1.010666095622807</th>\n",
       "      <th>1.0115813746251994</th>\n",
       "      <th>1.0119421506991577</th>\n",
       "      <th>...</th>\n",
       "      <th>6.202391618786217</th>\n",
       "      <th>6.233974953060784</th>\n",
       "      <th>6.294513284351789</th>\n",
       "      <th>6.396187345707123</th>\n",
       "      <th>6.402145481249871</th>\n",
       "      <th>6.423688648072396</th>\n",
       "      <th>6.4525647491669</th>\n",
       "      <th>6.511751311508908</th>\n",
       "      <th>6.643587523803953</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.175</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.225</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.275</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.325</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.956</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.959</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.00001</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1336</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2635 rows × 4858 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted  1.0067065336828516  1.0075261674184892  1.0088308245427258  \\\n",
       "real                                                                    \n",
       "0.175                       0                   0                   0   \n",
       "0.225                       1                   0                   0   \n",
       "0.25                        1                   0                   0   \n",
       "0.275                       1                   0                   0   \n",
       "0.325                       1                   0                   0   \n",
       "...                       ...                 ...                 ...   \n",
       "4.956                       0                   0                   0   \n",
       "4.959                       0                   0                   0   \n",
       "5.0                         0                   0                   0   \n",
       "5.00001                     1                   0                   0   \n",
       "All                      1336                   1                   1   \n",
       "\n",
       "predicted  1.0088450955681576  1.0097351029747441  1.0100842996797554  \\\n",
       "real                                                                    \n",
       "0.175                       0                   0                   0   \n",
       "0.225                       0                   0                   0   \n",
       "0.25                        0                   0                   0   \n",
       "0.275                       0                   0                   0   \n",
       "0.325                       0                   0                   0   \n",
       "...                       ...                 ...                 ...   \n",
       "4.956                       0                   0                   0   \n",
       "4.959                       0                   0                   0   \n",
       "5.0                         0                   0                   0   \n",
       "5.00001                     0                   0                   0   \n",
       "All                         1                   1                   1   \n",
       "\n",
       "predicted  1.0102444642468156  1.010666095622807  1.0115813746251994  \\\n",
       "real                                                                   \n",
       "0.175                       0                  0                   0   \n",
       "0.225                       0                  0                   0   \n",
       "0.25                        0                  0                   0   \n",
       "0.275                       0                  0                   0   \n",
       "0.325                       0                  0                   0   \n",
       "...                       ...                ...                 ...   \n",
       "4.956                       0                  0                   0   \n",
       "4.959                       0                  0                   0   \n",
       "5.0                         0                  0                   0   \n",
       "5.00001                     0                  0                   0   \n",
       "All                         1                  1                   1   \n",
       "\n",
       "predicted  1.0119421506991577  ...  6.202391618786217  6.233974953060784  \\\n",
       "real                           ...                                         \n",
       "0.175                       0  ...                  0                  0   \n",
       "0.225                       0  ...                  0                  0   \n",
       "0.25                        0  ...                  0                  0   \n",
       "0.275                       0  ...                  0                  0   \n",
       "0.325                       0  ...                  0                  0   \n",
       "...                       ...  ...                ...                ...   \n",
       "4.956                       0  ...                  0                  0   \n",
       "4.959                       0  ...                  0                  0   \n",
       "5.0                         0  ...                  0                  0   \n",
       "5.00001                     0  ...                  1                  1   \n",
       "All                         1  ...                  1                  1   \n",
       "\n",
       "predicted  6.294513284351789  6.396187345707123  6.402145481249871  \\\n",
       "real                                                                 \n",
       "0.175                      0                  0                  0   \n",
       "0.225                      0                  0                  0   \n",
       "0.25                       0                  0                  0   \n",
       "0.275                      0                  0                  0   \n",
       "0.325                      0                  0                  0   \n",
       "...                      ...                ...                ...   \n",
       "4.956                      0                  0                  0   \n",
       "4.959                      0                  0                  0   \n",
       "5.0                        0                  0                  0   \n",
       "5.00001                    1                  1                  1   \n",
       "All                        1                  1                  1   \n",
       "\n",
       "predicted  6.423688648072396  6.4525647491669  6.511751311508908  \\\n",
       "real                                                               \n",
       "0.175                      0                0                  0   \n",
       "0.225                      0                0                  0   \n",
       "0.25                       0                0                  0   \n",
       "0.275                      0                0                  0   \n",
       "0.325                      0                0                  0   \n",
       "...                      ...              ...                ...   \n",
       "4.956                      0                0                  0   \n",
       "4.959                      0                0                  0   \n",
       "5.0                        0                0                  0   \n",
       "5.00001                    1                1                  1   \n",
       "All                        1                1                  1   \n",
       "\n",
       "predicted  6.643587523803953   All  \n",
       "real                                \n",
       "0.175                      0     1  \n",
       "0.225                      0     1  \n",
       "0.25                       0     1  \n",
       "0.275                      0     1  \n",
       "0.325                      0     2  \n",
       "...                      ...   ...  \n",
       "4.956                      0     2  \n",
       "4.959                      0     1  \n",
       "5.0                        0     9  \n",
       "5.00001                    1   284  \n",
       "All                        1  6192  \n",
       "\n",
       "[2635 rows x 4858 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'predicted': mlpR.predict(X_test),\n",
    "             'real': y_test})\n",
    "\n",
    "pd.crosstab(index=df['real'], columns=df['predicted'], margins=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44513ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38837536501194614"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(df['real'],df['predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb644f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
