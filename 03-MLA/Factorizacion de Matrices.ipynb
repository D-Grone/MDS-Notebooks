{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72413d86",
   "metadata": {},
   "source": [
    "## Factorizacion de Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab24f6a6",
   "metadata": {},
   "source": [
    "Primero creemos una matriz de dise√±o inicial con valores aleatorios entre 0.1 y 0.9. Tambien creemos la funcion del error cuadratico medio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d326178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class matrix_factorization():\n",
    "    \n",
    "    def __init__(self,data,features):\n",
    "        self.data = data\n",
    "        self.features = features\n",
    "        self.user_count = data.shape[0]\n",
    "        self.item_count = data.shape[1]\n",
    "        self.user_features = np.random.uniform(low=0.1,high = 0.9, size = (self.user_count,self.features))\n",
    "        self.item_features = np.random.uniform(low=0.1,high = 0.9, size = (self.features,self.item_count))\n",
    "        \n",
    "    def MSE(self):\n",
    "        \"\"\"\n",
    "        Mean Squared Error function comparing dot product of user-feature row and feature-item column to user-item cell\n",
    "        \"\"\"\n",
    "        \n",
    "        matrix_product = np.matmul(self.user_features,self.item_features)\n",
    "        return np.sum((self.data - matrix_product)**2)\n",
    "\n",
    "\n",
    "    def single_gradient(self,user_row,item_col,wrt_user_idx = None, wrt_item_idx = None):\n",
    "        \"\"\"\n",
    "        Calcula el gradiente de un unica celda usuario-item a una unica celda usuario-feature o item-feature\n",
    "        \"\"\"\n",
    "        \n",
    "        if wrt_user_idx !=None and wrt_item_idx !=None:\n",
    "            return \"Too many elements\"\n",
    "        elif wrt_user_idx ==None and wrt_item_idx ==None:\n",
    "            return \"insufficient elements\"\n",
    "        else:\n",
    "            u_row = self.user_features[user_row,:]\n",
    "            i_col = self.item_features[:,item_col]\n",
    "            ui_rating = float(self.data[user_row,item_col])\n",
    "            prediction = float(np.dot(u_row,i_col))\n",
    "            \n",
    "            if wrt_user_idx != None:\n",
    "                row_elem = float(i_col[wrt_user_idx])\n",
    "                gradient = 2*(ui_rating-prediction)*row_elem\n",
    "            else:\n",
    "                col_elem = float(u_row[wrt_item_idx])\n",
    "                gradient = 2*(ui_rating-prediction)*col_elem\n",
    "            return gradient\n",
    "        \n",
    "    def user_feature_gradient(self,user_row,wrt_user_idx):\n",
    "        \"\"\"\n",
    "        Averages the gradients of a single user-item row with respect to a single user-feature parameter\n",
    "        \"\"\"\n",
    "        \n",
    "        summation = 0\n",
    "        for col in range(0,self.item_count):\n",
    "            summation += self.single_gradient(user_row = user_row,item_col=col,wrt_user_idx=wrt_user_idx)\n",
    "        return summation/self.item_count\n",
    "    \n",
    "    def item_feature_gradient(self,item_col,wrt_item_idx):\n",
    "        \"\"\"\n",
    "        Averages the gradients of a single user-item column with respect to a single feature-item parameter\n",
    "        \"\"\"\n",
    "        \n",
    "        summation = 0\n",
    "        for row in range(0,self.user_count):\n",
    "            summation += self.single_gradient(user_row = row,item_col=item_col,wrt_item_idx=wrt_item_idx)\n",
    "        return summation/self.user_count\n",
    "    \n",
    "    def update_user_feature(self,learning_rate):\n",
    "        \"\"\"\n",
    "        Updates every user-feature parameter according to supplied learning rate\n",
    "        \"\"\"\n",
    "        for i in range(0, self.user_count):\n",
    "            for j in range(0,self.features):\n",
    "                self.user_features[i,j] += learning_rate*self.user_feature_gradient(user_row=i,wrt_user_idx=j)\n",
    "        \n",
    "    def update_item_feature(self,learning_rate):\n",
    "        \"\"\"\n",
    "        Updates every feature-item parameter according to supplied learning rate\n",
    "        \"\"\"\n",
    "        for i in range(0, self.features):\n",
    "            for j in range(0,self.item_count):\n",
    "                self.item_features[i,j] += learning_rate*self.item_feature_gradient(item_col=j,wrt_item_idx=i)\n",
    "\n",
    "    ### Metodo de entrenamiento\n",
    "    \n",
    "    def train_model(self,learning_rate=0.1,iterations = 1000):\n",
    "        \"\"\"\n",
    "        Trains model, outputting MSE cost/loss every 50 iterations, using supplied learning and iterations\n",
    "        \"\"\"\n",
    "        for i in range(iterations):\n",
    "            self.update_user_feature(learning_rate=learning_rate)\n",
    "            self.update_item_feature(learning_rate=learning_rate)\n",
    "            if i %50 ==0:\n",
    "                print(self.MSE())\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16df16d4",
   "metadata": {},
   "source": [
    "Este es un programa de cero, veamos que pasa si creamos matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d691ef6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 3 1]\n",
      " [1 3 5]\n",
      " [3 5 1]]\n",
      "66.26235181326143\n",
      "3.538655335526818\n",
      "3.5386552492239662\n",
      "3.538655249223968\n",
      "3.5386552492239662\n",
      "3.5386552492239662\n",
      "3.5386552492239662\n",
      "3.5386552492239662\n",
      "3.5386552492239662\n",
      "3.5386552492239662\n",
      "3.5386552492239662\n",
      "3.5386552492239662\n",
      "3.5386552492239662\n",
      "3.5386552492239662\n",
      "3.5386552492239662\n",
      "3.5386552492239662\n",
      "3.5386552492239662\n",
      "3.5386552492239662\n",
      "3.5386552492239662\n",
      "3.5386552492239662\n"
     ]
    }
   ],
   "source": [
    "d = np.array([[5,3,1],[1,3,5],[3,5,1]])\n",
    "print(d)\n",
    "d2 = matrix_factorization(d,2)\n",
    "d2.train_model(learning_rate = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b37f79fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.28078016, 3.86133275, 0.55412635],\n",
       "       [0.8201476 , 3.21539   , 4.88850218],\n",
       "       [3.84015545, 3.99383559, 1.52084655]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(d2.user_features,d2.item_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1fbe30",
   "metadata": {},
   "source": [
    "Si consideramos un feature (caracteristica adicional), entonces nos mejora la descomposicion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb5f882d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 3 1]\n",
      " [1 3 5]\n",
      " [3 5 1]]\n",
      "47.142441246692094\n",
      "2.783028493521302e-09\n",
      "1.7644288402772858e-22\n",
      "1.2818989709841442e-30\n",
      "1.2818989709841442e-30\n",
      "1.2818989709841442e-30\n",
      "1.2818989709841442e-30\n",
      "1.2818989709841442e-30\n",
      "1.2818989709841442e-30\n",
      "1.2818989709841442e-30\n",
      "1.2818989709841442e-30\n",
      "1.2818989709841442e-30\n",
      "1.2818989709841442e-30\n",
      "1.2818989709841442e-30\n",
      "1.2818989709841442e-30\n",
      "1.2818989709841442e-30\n",
      "1.2818989709841442e-30\n",
      "1.2818989709841442e-30\n",
      "1.2818989709841442e-30\n",
      "1.2818989709841442e-30\n"
     ]
    }
   ],
   "source": [
    "d = np.array([[5,3,1],[1,3,5],[3,5,1]])\n",
    "print(d)\n",
    "d2 = matrix_factorization(d,3)\n",
    "d2.train_model(learning_rate = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "843b5e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 3., 1.],\n",
       "       [1., 3., 5.],\n",
       "       [3., 5., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(d2.user_features,d2.item_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3feeadc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ahora en Keras\n",
    "\n",
    "from __future__ import print_function, division\n",
    "from builtins import range, input\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9db69950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Dot, Add, Flatten\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b7f83a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'rating.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20592\\2024467231.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rating.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'rating.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('rating.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1129a36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620e0d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = df['userId'].value_counts().index\n",
    "map = {k:i for i, k in enumerate(user)}\n",
    "df['userId'] = df['userId'].map(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61eb84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mov = df['movieId'].value_counts().index\n",
    "map = {k:i for i, k in enumerate(mov)}\n",
    "df['movieId'] = df['movieId'].map(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081c0f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = df['userId'].max()\n",
    "M = df['movieId'].max()\n",
    "\n",
    "df.drop('timestamp', axis = 1, inplace = True)\n",
    "\n",
    "N,M\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f743c9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "m = 800\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c3646f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ucount = Counter(df['userId'])\n",
    "mcount = Counter(df['movieId'])\n",
    "\n",
    "uid = [u for u, c in ucount.most_common(n)]\n",
    "mid = [u for u, c in mcount.most_common(m)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5669e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = df[df['userId'].isin(uid) & df['movieId'].isin(mid)]\n",
    "newdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcb8774",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = newdf['userId'].max()\n",
    "M = newdf['movieId'].max()\n",
    "\n",
    "user = newdf['userId'].value_counts().index\n",
    "map = {k:i for i, k in enumerate(user)}\n",
    "newdf['userId'] = newdf['userId'].map(map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d5ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "mov = newdf['movieId'].value_counts().index\n",
    "map = {k:i for i, k in enumerate(mov)}\n",
    "newdf['movieId'] = newdf['movieId'].map(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038a1a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = shuffle(newdf)\n",
    "cutoff = int(0.8*len(newdf))\n",
    "cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caaa89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = newdf.iloc[: cutoff]\n",
    "test = newdf.iloc[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23216e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "mu = newdf['rating'].mean()\n",
    "epochs = 25\n",
    "reg = 0.\n",
    "N = 1000\n",
    "M = 800"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1306af",
   "metadata": {},
   "source": [
    "# KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd16167",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = Input(shape=(1,))\n",
    "m = Input(shape=(1,))\n",
    "\n",
    "u_embed = Embedding(N, K, embeddings_regularizer = l2(reg))(u) # size (N,1,K)\n",
    "m_embed = Embedding(M, K, embeddings_regularizer = l2(reg))(m) # size (M,1,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6555e50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_bias = Embedding(N, 1, embeddings_regularizer = l2(reg))(u)\n",
    "m_bias = Embedding(M, 1, embeddings_regularizer = l2(reg))(m)\n",
    "\n",
    "x = Dot(axes = 2)([u_embed, m_embed])\n",
    "\n",
    "x = Add()([x, u_bias, m_bias])\n",
    "x = Flatten()(x) # N,1\n",
    "\n",
    "model = Model(inputs = (u, m),\n",
    "             outputs = x)\n",
    "\n",
    "model.compile(loss = 'mse',\n",
    "             optimizer = Adam(learning_rate = 0.01),\n",
    "             metrics = ['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9c2ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = model.fit(x = [train['userId'].values, train['movieId'].values],\n",
    "                 y = train['rating'].values - mu,\n",
    "                 epochs = epochs,\n",
    "                 batch_size = 256,\n",
    "                 validation_data = ([test['userId'].values, test['movieId'].values],\n",
    "                 test['rating'].values - mu)\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d142219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses\n",
    "plt.plot(r.history['loss'], label=\"train loss\")\n",
    "plt.plot(r.history['val_loss'], label=\"test loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot mse\n",
    "plt.plot(r.history['mse'], label=\"train mse\")\n",
    "plt.plot(r.history['val_mse'], label=\"test mse\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94582c3b",
   "metadata": {},
   "source": [
    "## OTRO KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e94fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import dump_svmlight_file\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import urllib\n",
    "import zipfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4bd843",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('ml-100k/u.data',sep='\\t',names=\"user_id,item_id,rating,timestamp\".split(\",\"))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29266a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.user_id = dataset.user_id.astype('category').cat.codes.values\n",
    "dataset.item_id = dataset.item_id.astype('category').cat.codes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d859872",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataset, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65794382",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4934c14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users, n_movies = len(dataset.user_id.unique()), len(dataset.item_id.unique())\n",
    "n_latent_factors = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880565ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_input = keras.layers.Input(shape=[1],name='Item')\n",
    "movie_embedding = keras.layers.Embedding(n_movies + 1, n_latent_factors, name='Movie-Embedding')(movie_input)\n",
    "movie_vec = keras.layers.Flatten(name='FlattenMovies')(movie_embedding)\n",
    "user_input = keras.layers.Input(shape=[1],name='User')\n",
    "user_vec = keras.layers.Flatten(name='FlattenUsers')(keras.layers.Embedding(n_users + 1, n_latent_factors,name='User-Embedding')(user_input))\n",
    "prod = keras.layers.dot([movie_vec, user_vec], axes=1,name='DotProduct')\n",
    "model = keras.Model([user_input, movie_input], prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378169a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f629777",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766c69c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef3a386",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit([train.user_id, train.item_id], train.rating, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2a9e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(history.history['loss']).plot(logy=True)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbe065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate((test.user_id, test.item_id), test.rating, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c62da03",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_embedding_learnt = model.get_layer(name='Movie-Embedding').get_weights()[0]\n",
    "pd.DataFrame(movie_embedding_learnt).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cd9b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embedding_learnt = model.get_layer(name='User-Embedding').get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f265f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(user_id, number_of_movies=5):\n",
    "    movies = user_embedding_learnt[user_id]@movie_embedding_learnt.T\n",
    "    mids = np.argpartition(movies, -number_of_movies)[-number_of_movies:]\n",
    "    return mids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bbcb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend(user_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2673bb1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
