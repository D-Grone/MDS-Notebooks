{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONKTp2H0LTvz"
   },
   "source": [
    "# **Tarea 1**\n",
    "## Machine Learning Avanzado\n",
    "Integrantes: Patricio Ramirez\n",
    "             Carlos Bustamante\n",
    "             Nicolas Rivera\n",
    "             Pablo Elgueta\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Bxvw-PXNYdu"
   },
   "source": [
    "##### Objetivo:\n",
    "En este laboratorio volveremos a ver la biblioteca del trimestre anterior de perros y gatos. la base de datos de imagenes se\n",
    "encuentra en la siguiente dirección: ‘https://www.kaggle.com/competitions/dogs-vs-cats/data‘\n",
    "Ademas, para completar el análisis, se le pide construir una red que permita hacer la clasificación en base a los audios\n",
    "adicionalmente: ‘https://www.kaggle.com/datasets/mmoreaux/audio-cats-and-dogs‘ \n",
    "\n",
    "###### Se le evaluará por:\n",
    "\n",
    "- Carga y lectura de imagenes\n",
    "- Crear una red neuronal convolucional\n",
    "- Crear una red neuronal LSTM\n",
    "- Pruebe 2 formas distintas de arquitectura de red para cada una.\n",
    "- Cargue dos fotos de su biblioteca (sí, vaya y saque una foto a un perro o gato).\n",
    "- Evalúe sus modelos con las fotos sacadas.\n",
    "- Cargue los datos de audio\n",
    "- Proponga un modelo para clasificar este tipo de dato\n",
    "- Evalúe su modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFcTdPzdQqvi"
   },
   "source": [
    "### Dogs vs Cats\n",
    "\n",
    "#### **Descripción Dataset**\n",
    "\n",
    "\n",
    "- El archivo de entrenamiento contiene 25.000 imagenes de perros y gatos. \n",
    "- Entrena tu algoritmo con estos archivos y predice las etiquetas para test1.zip \n",
    "\n",
    "#### **Etiquetas:**\n",
    "\n",
    "- 1 = dog \n",
    "- 0 = cat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GGcnCC0UTcq9"
   },
   "source": [
    "## 1.-Reconocimiento e importación de librerías\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1hHs4kkfdnD"
   },
   "source": [
    "Para manipular bases de datos se usó Pandas, para visualización fueron las librerías Matplotlib y Seaborn, y en cuanto a Machine Learning se utilizó Keras y Scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gVzlvDlYaICU",
    "outputId": "8d998c8b-670f-4a84-b844-03b761213a30"
   },
   "outputs": [],
   "source": [
    "#import opendatasets as od\n",
    "\n",
    "#Analisis de Datos\n",
    "\n",
    "#import pandas as pd\n",
    "#import math\n",
    "#import numpy as np\n",
    "#import random\n",
    "\n",
    "#Visualizacion de Datos\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "#Machine Learning\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#import keras\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense\n",
    "#from keras import models, layers, optimizers, regularizers\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "#import tensorflow as tf\n",
    "#from tqdm import tqdm\n",
    "#sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "\n",
    "\n",
    "#test = pd.read_csv(\"/home/pato/Magister Data Science/Tercer Trimestre Data Science/ML Avanzado/Tareas/titanic/test.csv\")\n",
    "#train = pd.read_csv(\"/home/pato/Magister Data Science/Tercer Trimestre Data Science/ML Avanzado/Tareas/titanic/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuevas\n",
    "\n",
    "from matplotlib.image import imread\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.-Cargando el Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Descarga de Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'od' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mod\u001b[49m\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.kaggle.com/competitions/dogs-vs-cats/data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musername\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdgrone\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m8e16739c70ce24ea1e6d9a45b61e9796\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n",
      "\u001b[1;31mNameError\u001b[0m: name 'od' is not defined"
     ]
    }
   ],
   "source": [
    "od.download(\"https://www.kaggle.com/competitions/dogs-vs-cats/data\")\n",
    "{\"username\":\"dgrone\",\"key\":\"8e16739c70ce24ea1e6d9a45b61e9796\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zip(file, folder, password):\n",
    "    import zipfile\n",
    "    ruta_zip = file\n",
    "    ruta_extraccion = folder\n",
    "    archivo_zip = zipfile.ZipFile(ruta_zip, 'r')\n",
    "    try:\n",
    "        archivo_zip.extractall(pwd=password, path=ruta_extraccion)\n",
    "    except:\n",
    "        pass\n",
    "    archivo_zip.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Descompresión de Archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "folder = 'dogs-vs-cats/train/'\n",
    "if 'train' not in  listdir('dogs-vs-cats/'):\n",
    "    file = 'dogs-vs-cats/train.zip'\n",
    "    password = None\n",
    "    folder = 'dogs-vs-cats'\n",
    "    extract_zip(file, folder, password)\n",
    "    folder = 'dogs-vs-cats/train/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Visualización de Imagenes del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    pyplot.subplot(130  + 1 + i)\n",
    "    filename = folder + 'dog.' + str(i) + '.jpg'\n",
    "    image = imread(filename)\n",
    "    pyplot.imshow(image)\n",
    "pyplot.show()\n",
    "\n",
    "for i in range(3):\n",
    "    pyplot.subplot(130  + 1 + i)\n",
    "    filename = folder + 'cat.' + str(i) + '.jpg'\n",
    "    image = imread(filename)\n",
    "    pyplot.imshow(image)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Conversión de Imagen a Arreglo de Pixeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from os import listdir\n",
    "\n",
    "#i=0\n",
    "photos = list()\n",
    "labels = list()\n",
    "for file in listdir(folder):   # en versión final se debe reemplazar por file in listdir(folder), hay que probar\n",
    "    photo = load_img(folder + file, target_size=(40, 40))\n",
    "    print(folder + file)\n",
    "    #image = imread(folder + file)\n",
    "    \n",
    "    #pyplot.imshow(image)\n",
    "    photo = img_to_array(photo)\n",
    "    photos.append(photo)\n",
    "    if file.startswith('dog'):\n",
    "        label = 1.0\n",
    "        labels.append(label)\n",
    "    if file.startswith('cat'):\n",
    "        label = 0.0\n",
    "        labels.append(label)\n",
    "photos = asarray(photos)\n",
    "labels = asarray(labels)\n",
    "print(photos.shape, labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Normalización de Pixeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photos = photos/255\n",
    "photos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import save\n",
    "from numpy import load\n",
    "save('dogs_vs_cats_photos.npy', photos)\n",
    "save('dogs_vs_cats_labels.npy', labels)\n",
    "photos = load('dogs_vs_cats_photos.npy')\n",
    "labels = load('dogs_vs_cats_labels.npy')\n",
    "print(photos.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.- Subconjuntos de Entrenamiento y Validación de Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(photos, labels,test_size=0.3,random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.- Ajuestes de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Definición de Parámetros para Compilación de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = photos[1].shape\n",
    "num_classes = 1\n",
    "batch_size = 128\n",
    "epochs=20 \n",
    "best_test_accuracy = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1.- Modelo CNN 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Definición del Modelo CNN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Definición del Modelo y Capas\n",
    "modeloCNN = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')])\n",
    "\n",
    "###### Compilación del Modelo\n",
    "modeloCNN.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ajuste del Modelo CNN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train the parameters\n",
    "history = modeloCNN.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose = 1, validation_data=(X_test,y_test) )\n",
    "\n",
    "# evaluate accuracy\n",
    "train_acc = modeloCNN.evaluate(X_train, y_train, batch_size=16)[1]\n",
    "test_acc = modeloCNN.evaluate(X_test, y_test, batch_size=16)[1]\n",
    "print('Training accuracy: %s' % train_acc)\n",
    "print('Testing accuracy: %s' % test_acc)\n",
    "\n",
    "losses = history.history['loss']\n",
    "\n",
    "plt.plot(range(len(losses)), losses, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_test_accuracy < test_acc:\n",
    "    best_test_accuracy = test_acc\n",
    "    model_best = modeloCNN\n",
    "\n",
    "print(f'MODELO:\\n-------------------------------------------------------------------')\n",
    "modeloCNN.summary()\n",
    "print(f'\\nPrecisión:{test_acc}' ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1.- Modelo CNN 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Definición del Modelo CNN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Definición del Modelo y Capas\n",
    "modeloCNN2 = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(250, activation='relu'),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')])\n",
    "\n",
    "###### Compilación del Modelo\n",
    "modeloCNN2.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(learning_rate=0.0013), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the parameters\n",
    "history = modeloCNN2.fit(X_train, y_train, epochs=epochs, batch_size=16)\n",
    "\n",
    "# evaluate accuracy\n",
    "train_acc = modeloCNN2.evaluate(X_train, y_train, batch_size=16)[1]\n",
    "test_acc = modeloCNN2.evaluate(X_test, y_test, batch_size=16)[1]\n",
    "print('Training accuracy: %s' % train_acc)\n",
    "print('Testing accuracy: %s' % test_acc)\n",
    "\n",
    "losses = history.history['loss']\n",
    "\n",
    "plt.plot(range(len(losses)), losses, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4X4lnewdWfn6",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if best_test_accuracy < test_acc:\n",
    "    best_test_accuracy = test_acc\n",
    "    model_best = modeloCNN2\n",
    "\n",
    "print(f'MODELO:\\n-------------------------------------------------------------------')\n",
    "modeloCNN2.summary()\n",
    "print(f'\\nPrecisión:{test_acc}' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "# Each MNIST image batch is a tensor of shape (batch_size, 28, 28).\n",
    "# Each input sequence will be of size (28, 28) (height is treated like time).\n",
    "input_dim = 28\n",
    "\n",
    "units = 64\n",
    "output_size = 10  # labels are from 0 to 9\n",
    "\n",
    "# Build the RNN model\n",
    "def build_model(allow_cudnn_kernel=True):\n",
    "    # CuDNN is only available at the layer level, and not at the cell level.\n",
    "    # This means `LSTM(units)` will use the CuDNN kernel,\n",
    "    # while RNN(LSTMCell(units)) will run on non-CuDNN kernel.\n",
    "    if allow_cudnn_kernel:\n",
    "        # The LSTM layer with default options uses CuDNN.\n",
    "        lstm_layer = keras.layers.LSTM(units, input_shape=(None, input_dim))\n",
    "    else:\n",
    "        # Wrapping a LSTMCell in a RNN layer will not use CuDNN.\n",
    "        lstm_layer = keras.layers.RNN(\n",
    "            keras.layers.LSTMCell(units), input_shape=(None, input_dim)\n",
    "        )\n",
    "    model = keras.models.Sequential(\n",
    "        [\n",
    "            lstm_layer,\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dense(output_size),\n",
    "        ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLSTM = build_model(allow_cudnn_kernel=True)\n",
    "\n",
    "modelLSTM.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "\n",
    "modelLSTM.fit(\n",
    "    x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=1\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
